# brokkctl — CLI Controller Specification (Spike)

This document specifies a small, focused CLI controller — working name `brokkctl` — that discovers and talks to running Brokk desktop processes and presents a machine-friendly, JSON-first automation surface. This is a specification-only spike: it defines the surface, semantics, and versioning rules needed to implement a CLI controller and compatible MCP/REST/AppleScript endpoints. It does not prescribe implementation details or require changes to Brokk internals.

## Overview

`brokkctl` is an orchestration layer intended for automation and scripting. Its responsibilities are:

- Discover local Brokk instances that expose a control endpoint.
- Send commands to one or more instances and aggregate responses.
- Provide a stable, machine-readable JSON API for automation; human-friendly output is optional.
- Negotiate capabilities and compatibility via a lightweight protocol version.

This spec is implementation-agnostic: discovery can be implemented by registry, socket probing, mDNS, or another platform-appropriate mechanism. The important part is the semantics and compatibility guarantees offered to clients.

## Goals

- Define a stable, machine-friendly CLI surface for common automation tasks:
  - Instance discovery and selection
  - Project open/list/get actions
  - Session create/list/get/import/export
  - Context manipulation (add files/classes/methods/text)
  - Querying session output / history
  - Execution control: run one-off executions (ASK, CODE) and plan/run task lists (PLAN, LUTZ)
  - Task list management: CRUD the current session task list and control task execution (start/stop/status)
- Make JSON the canonical output mode (`-o json`), with NDJSON for streaming event feeds.
- Support multi-instance fan-out with well-defined per-instance and aggregate results.
- Provide a versioned protocol and compatibility policy enabling graceful client and server evolution.
- Produce a concise, testable spec to guide implementations in the application and a standalone `brokkctl` tool.

## Non-goals

- This is a spec-only spike. It does not modify application core logic, private storage formats, or internal behavior.
- The spec does not mandate a discovery transport (mDNS vs sockets vs registry). Implementers choose platform-appropriate mechanisms.
- This document does not provide exhaustive CLI UX text (help output). Those are implementation details.
- No runtime behavioral changes to the Brokk desktop application are required by this spec.

## Terminology

- instance  
  A running Brokk process that exposes a local control endpoint (MCP/HTTP/stdio). An instance is identified by an `instanceId` and a discovery descriptor (listen address, PID when available, socket path, etc.).

- project  
  A code workspace opened in an instance. Instances may have zero, one, or multiple projects open at the same time.

- projects  
  The set of projects currently open in an instance. When a single "active" project is needed for display or default scoping, instances may additionally report a `project` field as a convenience alias for the most recently active project.

- session  
  A Brokk session (user session) representing a workspace snapshot, context, configuration, and transcript/history. Sessions are created, imported, exported, and selected inside an instance.

- context  
  Additional data seeded into a session to influence LLM reasoning: files, class summaries, method sources, or free-form text fragments. Context entries are addressable (IDs) and may be session- or job-scoped.

- history  
  The session transcript and action history: sequence of task entries, LLM outputs, notifications, diffs, and related metadata. Useful for resuming work or exporting results.

- execution  
  A unit of work submitted to an instance for processing. Executions have modes (ASK, CODE, PLAN, LUTZ), accept a session-scoped request (instructions + optional model/run options), may produce streamable events, and end with a terminal status plus optional artifacts (diffs, task lists, etc.).

- task list  
  A session-scoped ordered list of tasks representing work items for a project/session. PLAN and LUTZ create or update the current session task list. LUTZ may additionally execute the task list automatically. The task list supports CRUD operations via brokkctl so automation can inspect, edit, and control it.

## CLI Command Surface (conceptual)

Top-level command: `brokkctl`

Global flags:
- `--format json|text` — output format; `json` is the canonical machine-friendly default. `text` yields human-oriented pretty output.
- `--instance <selector>` — target a specific instance. Supported selector forms: instanceId (UUID), `pid:<n>`, `addr:<host:port>`, `socket:<path>`.
- `--all` — target all non-stale instances (fan-out).
- `--timeout <ms>` — overall timeout in milliseconds for discovery and per-request network operations (default: 30000).
- `--fail-fast` / `--best-effort` — fan-out failure policy. `--fail-fast` aborts on first failure (default); `--best-effort` attempts all targets and returns an aggregated result (partial success possible).
- `--protocol-version <MAJOR.MINOR.PATCH>` — advertise a specific client protocol version via the `Brokk-CTL-Version` header; if omitted the client will use its built-in version.
- `--allow-incompatible` — explicitly allow proceeding when client MAJOR > server MAJOR (dangerous; requires opt-in).

Example subcommands (conceptual):
- `brokkctl instances list` — list discovered instances
- `brokkctl project open --path <path>` — open a project in an instance
- `brokkctl sessions create --name <name>` — create a session
- `brokkctl sessions import --file <session.zip>` — import a session zip
- `brokkctl context add-file --path <relPath>` — add files to session context
- `brokkctl execution submit --session <id> --mode <MODE> --planner-model <model> --task "..."` — submit a job
- `brokkctl execution events --job <jobId> --follow` — stream job events (NDJSON)
- `brokkctl execution cancel --job <jobId>` — cancel job
- `brokkctl history get --session <id> --limit N` — fetch session history

All commands must support `-o json` and return structured JSON for automation. Streaming endpoints should use NDJSON or SSE with an option to pass through raw server stream.

## Discovery & Multi-instance Handling

Discovery semantics:
- `brokkctl` must discover zero or more instances and return descriptors with:
  - `instanceId` (string)
  - `pid` (optional)
  - `listenAddr` (host:port or socket path)
  - `projects` (if available): array of open project/workspace root paths
  - `project` (optional): convenience alias for the active/most-recent project path (clients should prefer `projects`)
  - `brokkctlVersion` (protocol version the instance speaks)
  - `lastSeenMs` (timestamp hint for stability)

Registry location
- The instance registry is per-user and uses the platform's conventional user config directory. Implementations SHOULD store instance records as individual files in a directory to avoid write-contention and to allow atomic add/remove. Recommended locations:
  - Linux: `$XDG_CONFIG_HOME/brokk/instances/` (fallback: `$HOME/.config/brokk/instances/`)
  - macOS: `~/Library/Application Support/Brokk/instances/`
  - Windows: `%APPDATA%\Brokk\instances\`
- Each instance writes a single file named `<instanceId>.json` into the registry directory. Files MUST be written atomically (write temporary file then rename) to avoid partial reads.

Local shared key
- Because this controller is used locally, it does not use bearer tokens. Instead, the instance and `brokkctl` authenticate using a shared local key stored on disk in a well-known per-user location.
- Recommended key file locations:
  - Linux: `$XDG_CONFIG_HOME/brokk/ctl.key` (fallback: `$HOME/.config/brokk/ctl.key`)
  - macOS: `~/Library/Application Support/Brokk/ctl.key`
  - Windows: `%APPDATA%\Brokk\ctl.key`
- Key format:
  - UTF-8 text file containing a single opaque random string (for example, 32+ bytes of randomness encoded as hex or base64url).
  - No trailing metadata; readers should trim whitespace.
- Generation:
  - On first run, `brokkctl` (or the first instance) SHOULD create the key file if absent.
  - File permissions SHOULD be user-only (best-effort per platform).
- Request authentication:
  - HTTP clients MUST send `Brokk-CTL-Key: <key>` on each request to an instance control endpoint.
  - Instances MUST read the key file and compare for equality (after trimming). If missing or mismatched, reject with `UNAUTHORIZED`.
- Rotation:
  - Deleting the file rotates the key; new key creation invalidates existing clients until they reload the file.

Record schema
- Each `<instanceId>.json` file is a JSON object with the following fields:
  - `instanceId` (string, required): stable instance identifier (UUID recommended).
  - `pid` (number|null): process id of the instance when available.
  - `listenAddr` (string, required): transport address (e.g., `127.0.0.1:54321` or `/tmp/brokk.sock`).
  - `projects` (array|null): optional list of open project/workspace root paths.
  - `project` (string|null): optional active/most-recent project path (convenience alias; clients should prefer `projects`).
  - `brokkctlVersion` (string): protocol version the instance advertises (semantic-ish `MAJOR.MINOR.PATCH`).
  - `supportedCapabilities` (optional array): capability descriptors the instance returns.
  - `startedAt` (number): epoch ms when the instance started.
  - `lastSeenMs` (number): epoch ms of the most recent heartbeat/update from the instance.
  - `platform` (optional string): short platform hint (e.g., `linux`, `darwin`, `windows`).
  - `listenProtocol` (optional string): e.g., `http`, `unix`, `namedpipe`.
- Example file name: `550e8400-e29b-41d4-a716-446655440000.json`

Heartbeat and TTL
- Instances MUST update `lastSeenMs` periodically (heartbeat). A reasonable default heartbeat interval is 5 seconds.
- `brokkctl` and other readers SHOULD consider an entry stale if `now - lastSeenMs > TTL`. Recommended default TTL: 30 seconds.
- On clean shutdown the instance SHOULD remove its file from the registry directory. Files left behind (unremoved) will be treated as stale and will be pruned.

Cleanup rules
- Because instances may crash or be killed, registry cleanup is cooperative:
  - Instances remove their file on clean exit.
  - Readers (like `brokkctl`) SHOULD ignore stale entries older than TTL.
  - `brokkctl` MAY expose a `instances prune` command that removes stale files (only when run by the same user who owns the registry directory).
  - Implementations SHOULD provide safe atomic deletion (unlink) and avoid assuming permission to modify other users' entries.
- Filesystem semantics:
  - Use one file per instance to allow simple atomic create/replace/delete semantics.
  - When updating, write to a temporary file and rename to replace the prior file atomically.

Selection rules and CLI flags
- `--instance <selector>`: select a specific instance. The selector formats supported SHOULD include:
  - Instance ID (UUID): `550e84...`
  - PID selector: `pid:12345`
  - Listen address: `addr:127.0.0.1:54321` or raw `127.0.0.1:54321`
  - Socket path: `socket:/tmp/brokk.sock`
- `--all`: target all non-stale instances (fan-out). When used, results MUST be an aggregated shape with per-instance entries and a summary.
- `--auto-select`: non-interactive, deterministic auto-selection. When present, choose the instance using this deterministic priority:
  1. The sole non-stale instance, if exactly one exists.
  2. Instance with most recent `lastSeenMs`.
  3. Tie-breaker: highest `pid` (numeric) to make selection deterministic.
- Default behavior (no selector and no `--all`):
  - If zero non-stale instances found: return a deterministic error recommending `--instance` or `--auto-select`.
  - If exactly one non-stale instance found: select it automatically.
  - If multiple non-stale instances and running in an interactive TTY: prompt the user to choose.
  - If multiple and non-interactive (e.g., scripts, CI): fail deterministically and require `--instance`, `--all`, or `--auto-select`.
- Interaction semantics:
  - Interactive prompts MUST include `instanceId`, `pid`, `listenAddr`, and `brokkctlVersion`, and either:
    - the `project` convenience field when present, or
    - a compact summary of `projects` (for example: active + count, or first N paths + count) to help the user choose.

Fan-out semantics and aggregation
- `instances list` is naturally fan-out and returns raw discovery records.
- Operational commands target a single instance by default. If a command supports explicit multi-instance execution, results MUST include:
  - `summary`: { requested, succeeded, failed }
  - `results`: [{ instanceId, status, data?, error? }, ...]
- Mixed outcomes map to exit code `3` (partial failure) when `-o json` is used; otherwise the CLI should surface a clear message and a non-zero exit code.

Security:
- This controller is intended for local-only automation.
- Each instance and `brokkctl` MUST authenticate requests using a shared local key stored on disk (see "Local shared key"):
  - `brokkctl` loads the key from a well-known per-user file prior to each request.
  - The instance reads the same file and compares its contents to the key provided on the request.
  - If the keys do not match, the instance rejects the request with `UNAUTHORIZED`.
- Wire format:
  - HTTP transports MUST send `Brokk-CTL-Key: <key>` on every request.
  - Non-HTTP transports (MCP/AppleScript) MUST include `ctlKey` in the canonical request envelope payload or a transport-equivalent metadata channel.
- This mechanism is designed to prevent accidental leakage if an endpoint is reachable over HTTP; it is not intended as a remote security boundary.

Aggregation:
- For fan-out calls, return:
  - `summary`: { requested, succeeded, failed }
  - `results`: [{ instanceId, status, data?, error? }, ...]
- Mixed outcomes map to exit code `3` (partial failure) when `-o json` is used; otherwise the CLI should surface a clear message and a non-zero exit code.

## Output & Exit Codes

- `--format json` is the canonical machine format (use NDJSON for streaming/event feeds when `--follow` or similar is used).
- Human-friendly output (`text`) is a presentation-layer concern.
- For streaming events prefer NDJSON (newline-delimited JSON) for line-by-line tooling compatibility.

Exit code mapping (recommended):
- `0` — SUCCESS: All requested operations succeeded.
- `1` — USER_ERROR: Invalid arguments, missing required flags, or other client-side usage errors.
- `2` — TRANSPORT_ERROR: Network-level failures, request timeouts, or discovery failures.
- `3` — AUTH_ERROR: Authentication/authorization failures (e.g., 401/403).
- `4` — PARTIAL_SUCCESS: Fan-out operations completed with a mix of successes and failures.

Semantics and rules:
- Any non-zero exit code indicates failure for automation. `4` explicitly denotes partial success and allows callers to detect mixed outcomes.
- `--fail-fast`: the CLI should return immediately on the first error using the appropriate error category code (USER_ERROR/TRANSPORT_ERROR/AUTH_ERROR).
- `--best-effort`: the CLI should attempt all targets and then:
  - If at least one target succeeded and at least one failed, return `4` (PARTIAL_SUCCESS).
  - If all targets failed, return the highest-priority non-zero error encountered. Priority order for collapsing multiple error types: AUTH_ERROR (3) > TRANSPORT_ERROR (2) > USER_ERROR (1).
- In `json` mode error responses MUST follow the structured shape:
{
  "error": {
    "code": "USER_ERROR",
    "message": "Detailed text",
    "details": { ... optional ... }
  }
}
- For fan-out responses include a `summary` and per-instance `results` (each result may include `error`); in mixed-outcome cases return exit code `4`.

## Versioning Strategy — `brokkctl` Protocol

To enable safe evolution between clients (`brokkctl`) and instances, we introduce a lightweight protocol version header and negotiation rules.

Header name:
- `Brokk-CTL-Version` — included on discovery and all subsequent control requests/responses.

Version format:
- Semantic-ish: `MAJOR.MINOR.PATCH` (e.g., `1.0.0`).
  - MAJOR: breaking changes
  - MINOR: backward-compatible feature additions
  - PATCH: bug fixes only

Compatibility rules:
- Same MAJOR: client and server MAY attempt to proceed.
  - If server.MINOR >= client.MINOR: expected to support client's requested features.
  - If server.MINOR < client.MINOR: the server must return a structured error describing unsupported features (error code `PROTOCOL_UNSUPPORTED_FEATURE`) and list supported capabilities; the client should either degrade or abort.
- Different MAJOR:
  - If client.MAJOR < server.MAJOR: server MAY support older clients; client should be prepared for `PROTOCOL_UNSUPPORTED_FEATURE` errors.
  - If client.MAJOR > server.MAJOR: client SHOULD refuse to proceed automatically. Require `--allow-incompatible` to proceed (explicit opt-in).
- PATCH differences are safe; do not affect protocol semantics.

Negotiation:
- Discovery descriptors MUST include `brokkctlVersion`.
- Clients SHOULD include `Brokk-CTL-Version: <client-version>` in requests.
- Servers SHOULD respond with a `Brokk-CTL-Version` response header equal to their implemented version.
- If a requested capability is missing, the server responds with `HTTP 409` (or other appropriate status) and a JSON error body containing:
  - `code: "PROTOCOL_UNSUPPORTED_FEATURE"`
  - `message: "Feature X requires brokkctl >= MAJOR.MINOR"`
  - optional `supportedCapabilities` list with minimal required versions.

Backward-compatibility policies (quick reference):
- Client MAJOR == Server MAJOR:
  - Server.MINOR < Client.MINOR → client must detect unsupported capability errors and either degrade or abort with a clear explanation.
  - Server.MINOR >= Client.MINOR → features should work.
- Client MAJOR != Server MAJOR:
  - Client.MAJOR > Server.MAJOR → require explicit `--allow-incompatible`.
  - Client.MAJOR < Server.MAJOR → proceed but handle server-provided errors.
- Always expose server `brokkctlVersion` in CLI output so automation can adapt.

Capabilities declaration:
- Servers SHOULD expose a discovery endpoint (e.g., `GET /v1/ctl-info`) returning:
  - `brokkctlVersion` (string)
  - `instanceId`, `pid`, `projects`, `listenAddr`
  - `supportedCapabilities`: [{ "name": "sessions.switch", "minVersion": "1.0.0" }, ...]
- Clients can use `supportedCapabilities` to decide safe fallbacks.
- Servers MAY additionally expose phase capabilities to simplify client logic:
  - `{ "name": "phase.1", "minVersion": "1.0.0" }`
  - `{ "name": "phase.2", "minVersion": "1.0.0" }`
  - `{ "name": "phase.3", "minVersion": "1.0.0" }`
  These are convenience markers only; the authoritative source of truth is the set of supported command capabilities.

## Error Model

- Always return structured JSON errors in `-o json` mode.
- Distinguish discovery/network-level errors from operation-level errors.
- For fan-out operations return per-instance `error` and a top-level `summary`.
- Use consistent, enumerated error codes (e.g., `INVALID_ARGS`, `NOT_FOUND`, `UNAUTHORIZED`, `BUSY`, `PROTOCOL_UNSUPPORTED_FEATURE`, `INTERNAL_ERROR`).

## Phased rollout plan (MVP -> full surface)

This spec is intentionally larger than the initial implementation. Implementations SHOULD roll out in phases, and MUST declare supported commands via `supportedCapabilities` (see Versioning Strategy) so clients can degrade gracefully.

### Phase 1 (MVP: Claude Code delegation)

Goal: allow a local tool to delegate larger work to Brokk, by ensuring a project is open, creating/selecting a session, starting a PLAN/LUTZ run, and retrieving status/output.

Required commands and behaviors:
- `instances list`
  - Must return non-stale instances and their `projects` array (when available).
- `projects open`
  - Must open a project by absolute `--path`.
- `sessions active`, `sessions create`, `sessions switch`
  - Must allow deterministic session selection by `--session-id` and creation by `--name`.
- `exec start`
  - Must support at least `--mode plan` and SHOULD support `--mode lutz`.
  - Must return a `jobId` and a way to retrieve events (either streaming or poll).
- `state get`
  - Must report idle vs running and include `jobId` when running (if available).
- `history get` (required) and `history tail --follow` (recommended)
  - Must provide sufficient output for a delegating client to summarize progress and results.
- Error/compatibility requirements:
  - Servers MUST return `PROTOCOL_UNSUPPORTED_FEATURE` when asked for commands/flags they do not support.
  - Servers SHOULD include `supportedCapabilities` entries for each Phase 1 command.

Optional but recommended in Phase 1:
- NDJSON streaming for `exec start --follow` or `history tail --follow`.

### Phase 2 (Task list introspection and manual control)

Goal: allow callers to inspect and adjust the PLAN-generated task list and manually start/stop task execution.

Commands:
- `tasks get`, `tasks set`, `tasks add`, `tasks update`, `tasks remove`, `tasks clear`
- `taskrun start`, `taskrun stop`, `taskrun status`

### Phase 3 (Full surface / multi-instance workflows)

Goal: expand support for broader automation use cases and operational robustness.

Commands and capabilities:
- `context list/add/remove` advanced options (`--line-range`, content upload, etc.)
- richer history filtering/paging and cross-instance tails
- explicit `instances prune`
- best-effort multi-instance fan-out for operational commands where safe

## Next Steps (implementation hints)

- Implement a `ctl-info` discovery/health endpoint in the application that returns `brokkctlVersion`, instance metadata, and capabilities.
- Choose a platform-appropriate discovery mechanism for local instances.
- Implement Phase 1 JSON-first surfaces first; add human-friendly formatting later.
- Add tests that exercise negotiation rules:
  - Client requesting a MINOR-level feature against a lower-MINOR server
  - Major version mismatch handling and `--allow-incompatible` opt-in
  - Fan-out aggregation with mixed results
- Document recommended exit codes and JSON shapes for consumers (CI scripts, orchestration systems).

## JSON Envelope Schemas

This section defines the canonical JSON envelope shapes that `brokkctl` and Brokk instances should produce and accept for non-streaming operations. These envelopes standardize request correlation, per-instance results, aggregated fan-out responses, and error reporting so automation can reliably correlate and react to outcomes.

Top-level conventions
- Every client-initiated request SHOULD include a `requestId` (string, UUID recommended) to allow correlation across retries, logs, and aggregated responses.
- Per-instance results MUST include `instanceId` and a `status` field. If an instance returns an error, include an `error` object following the canonical Error shape below.
- Fan-out responses MUST include an aggregated `summary` and a `results` array with per-instance containers.
- For streaming endpoints use NDJSON where each line is a JSON envelope; each event line SHOULD include `requestId` and `instanceId` when applicable.

1) Canonical request envelope (client → instance)

```json
{
  "requestId": "550e8400-e29b-41d4-a716-446655440000",
  "createdAtMs": 1690000000000,
  "command": "execution.submit",
  "protocolVersion": "1.0.0",
  "payload": {
    /* command-specific body, e.g. JobSpec */
  }
}
```

Fields:
- `requestId` (string, required): opaque correlation id assigned by the client.
- `createdAtMs` (number, optional): epoch ms when the request was created.
- `command` (string, required): logical command name (e.g., `sessions.create`, `execution.submit`).
- `protocolVersion` (string, optional): client's `Brokk-CTL-Version` (MAJOR.MINOR.PATCH).
- `payload` (object, optional): command-specific parameters.

2) Canonical per-instance result container

```json
{
  "instanceId": "550e8400-e29b-41d4-a716-446655440000",
  "listenAddr": "127.0.0.1:54321",
  "status": "ok",
  "data": { /* optional success payload */ },
  "error": null,
  "elapsedMs": 123
}
```

Or on failure:

```json
{
  "instanceId": "550e8400-e29b-41d4-a716-446655440000",
  "listenAddr": "127.0.0.1:54321",
  "status": "error",
  "data": null,
  "error": {
    "code": "BUSY",
    "message": "instance is busy",
    "details": { "retryAfterMs": 5000 }
  },
  "elapsedMs": 45
}
```

Fields:
- `instanceId` (string, required): instance identifier.
- `listenAddr` (string, optional): endpoint used for the request (helpful for debugging).
- `status` (string, required): one of `"ok"`, `"error"`, or `"skipped"`.
- `data` (object|null): command-specific success payload when `status == "ok"`.
- `error` (Error|null): present when `status == "error"`; must follow the canonical Error shape.
- `elapsedMs` (number, optional): milliseconds the instance spent handling the request (instrumentation).

3) Canonical Error object shape

```json
{
  "code": "PROTOCOL_UNSUPPORTED_FEATURE",
  "message": "Feature 'sessions.import' requires brokkctl >= 1.1.0 (server: 1.0.0)",
  "details": {
    "serverVersion": "1.0.0",
    "requiredVersion": "1.1.0",
    "supportedCapabilities": [
      { "name": "sessions.create", "minVersion": "1.0.0" }
    ]
  }
}
```

Fields:
- `code` (string, required): short machine-friendly error code (enumerated values encouraged, e.g., `INVALID_ARGS`, `NOT_FOUND`, `UNAUTHORIZED`, `BUSY`, `PROTOCOL_UNSUPPORTED_FEATURE`, `INTERNAL_ERROR`).
- `message` (string, required): human-consumable explanation suitable for logs and UI.
- `details` (object, optional): structured diagnostic data helpful for programmatic decisions (versions, URLs, retry hints, capability lists, etc.).

4) Aggregate fan-out response (client receives)

```json
{
  "requestId": "550e8400-e29b-41d4-a716-446655440000",
  "summary": { "requested": 3, "succeeded": 2, "failed": 1 },
  "results": [
    {
      "instanceId": "a",
      "status": "ok",
      "data": { /* command-specific */ },
      "error": null
    },
    {
      "instanceId": "b",
      "status": "ok",
      "data": { /* command-specific */ },
      "error": null
    },
    {
      "instanceId": "c",
      "status": "error",
      "data": null,
      "error": {
        "code": "BUSY",
        "message": "instance is busy",
        "details": {}
      }
    }
  ],
  "elapsedMs": 215
}
```

Fields:
- `requestId` (string, required): mirrors the client's requestId for easy correlation.
- `summary` (object, required): aggregate counts `{ requested, succeeded, failed }`.
- `results` (array, required): array of per-instance result containers.
- `elapsedMs` (number, optional): overall time from the client's perspective.

Exit code mapping (json-mode)
- On all-success: exit code `0`.
- On per-instance mixed results: exit code `4` (PARTIAL_SUCCESS).
- On global failure: appropriate non-zero (see spec mapping for USER_ERROR, TRANSPORT_ERROR, AUTH_ERROR).

Streaming (NDJSON) variant
- For streaming endpoints (e.g., `execution events --follow`) use NDJSON where each line is either:
  - an event envelope: `{ "requestId": "...", "instanceId": "...", "eventType": "stdout|job.event|job.complete", "event": { ... } }`
  - or an error envelope: `{ "requestId": "...", "instanceId": "...", "error": { ... } }`
- Each NDJSON line MUST be parseable as a self-contained JSON object and SHOULD include `requestId` and `instanceId` when applicable.

5) Example: protocol unsupported feature error (uses canonical Error shape)

```json
{
  "requestId": "550e8400-e29b-41d4-a716-446655440000",
  "error": {
    "code": "PROTOCOL_UNSUPPORTED_FEATURE",
    "message": "Feature 'sessions.import' requires brokkctl >= 1.1.0 (server: 1.0.0)",
    "details": {
      "serverVersion": "1.0.0",
      "requiredVersion": "1.1.0",
      "supportedCapabilities": [
        { "name": "sessions.create", "minVersion": "1.0.0" }
      ]
    }
  }
}
```

## Instances list — command specification

This section specifies the `brokkctl instances list` command in detail: inputs, output schema, and example responses for the common cases (0, 1, many instances). It also documents how stale/unreachable instances are represented when `--all` is used.

Purpose
- Enumerate discovered Brokk instances visible to the current user.
- By default, return *non-stale* (i.e., "online") entries only. Use `--all` to include stale and potentially unreachable records left in the registry.

Inputs / Flags
- `--format json|text` (global): output format. `json` is canonical.
- `--all` (optional): include stale registry entries (entries older than the TTL). When omitted, stale entries are filtered out.
- `--ttl <ms>` (optional): override TTL used to decide staleness for this invocation (default: 30000 ms).
- `--request-id <uuid>` (optional): client-supplied requestId for correlation. If omitted, the client generates one.
- `--timeout <ms>` (optional): discovery timeout. Defaults to global timeout.

Behavioral rules
- Default (no `--all`): return only entries where `now - lastSeenMs <= TTL`.
- With `--all`: return all registry entries, but mark stale and unreachable entries with explicit status fields.
- If an entry appears stale (lastSeenMs older than TTL), the entry's `status` becomes `"stale"`. A stale entry may still be reachable if the client can connect to its `listenAddr`. The client SHOULD attempt a lightweight reachability probe (e.g., `ctl-info`) only when `--all` is used or when an explicit `--probe` flag is present (to avoid unnecessary network calls during discovery).
- If a previously-written registry file exists but the instance cannot be reached (connection refused, key mismatch, etc.), the entry `status` becomes `"unreachable"` and an `error` object is included describing the failure.

Output schema (JSON mode)
Top-level envelope for `-o json`:

```json
{
  "requestId": "550e8400-e29b-41d4-a716-446655440000",
  "summary": {
    "total": 3,
    "online": 1,
    "stale": 1,
    "unreachable": 1
  },
  "instances": [
    /* array of instance descriptors (see below) */
  ],
  "elapsedMs": 12
}
```

Instance descriptor (list entry)
```json
{
  "instanceId": "550e8400-e29b-41d4-a716-446655440000",
  "pid": 12345,
  "listenAddr": "127.0.0.1:54321",
  "projects": ["/home/alice/my-repo"],
  "project": "/home/alice/my-repo",
  "brokkctlVersion": "1.0.0",
  "startedAt": 1690000000000,
  "lastSeenMs": 1690000050000,
  "platform": "linux",
  "listenProtocol": "http",
  "status": "online",
  "stale": false,
  "probe": {
    "reachable": true,
    "serverVersion": "1.0.0",
    "latencyMs": 5
  },
  "error": null
}
```

Field notes:
- `status` (string): one of:
  - `"online"` — lastSeen within TTL and probe (when performed) succeeded or not performed.
  - `"stale"` — lastSeen older than TTL. When `--all` is used this is returned; otherwise stale entries are omitted.
  - `"unreachable"` — entry exists in registry but a probe to `listenAddr` failed (network error, auth error, etc.).
- `stale` (boolean): convenience boolean equivalent to `status == "stale"`.
- `probe` (optional object): results of a lightweight reachability probe (present only when probes are performed). Includes `reachable` (bool), `serverVersion`, and `latencyMs`.
- `error` (object|null): present when `status == "unreachable"` or when a probe returns an error. Follows canonical Error object shape (code/message/details).

Example `probe` failure/error (embedded in `error`)
```json
"error": {
  "code": "TRANSPORT_ERROR",
  "message": "connection refused",
  "details": {
    "attemptedAddr": "127.0.0.1:54321",
    "cause": "ECONNREFUSED"
  }
}
```

Behavior details for `--all`
- When `--all` is supplied:
  - Return all registry files, regardless of age.
  - Mark entries older than TTL with `status: "stale"` and `stale: true`.
  - Optionally perform reachability probes (see flags) to detect `unreachable` entries and populate `probe` and `error` fields. Probing increases latency and may require credentials if endpoints are secured; probes should only be performed when necessary (e.g., when `--probe` is explicitly passed, or when `--all --format json --verbose`).
  - `unreachable` entries are included only in `--all` view (they may also appear as `stale` if age exceeds TTL).

Examples

1) Zero instances (no registry files / nothing discovered)

Command:
- `brokkctl instances list -o json`

Output:
```json
{
  "requestId": "generated-or-empty",
  "summary": { "total": 0, "online": 0, "stale": 0, "unreachable": 0 },
  "instances": [],
  "elapsedMs": 5
}
```

Behavior: The CLI should return exit code `0` (success) and a helpful `text` message when not in JSON mode, e.g., "No Brokk instances found. Run Brokk or use --instance to target an instance."

2) Single online instance (normal case)

Command:
- `brokkctl instances list -o json`

Output:
```json
{
  "requestId": "550e8400-e29b-41d4-a716-446655440000",
  "summary": { "total": 1, "online": 1, "stale": 0, "unreachable": 0 },
  "instances": [
    {
      "instanceId": "550e8400-e29b-41d4-a716-446655440000",
      "pid": 12345,
      "listenAddr": "127.0.0.1:54321",
      "projects": ["/home/alice/my-repo", "/home/alice/my-other-repo"],
      "brokkctlVersion": "1.0.0",
      "startedAt": 1690000000000,
      "lastSeenMs": 1690000050000,
      "platform": "linux",
      "listenProtocol": "http",
      "status": "online",
      "stale": false,
      "probe": { "reachable": true, "serverVersion": "1.0.0", "latencyMs": 3 },
      "error": null
    }
  ],
  "elapsedMs": 8
}
```

Behavior: Exit code `0`. In `text` mode, show a compact table with the instanceId, pid, listenAddr, project, and version.

3) Many instances with mixed states (example using `--all`)

Command:
- `brokkctl instances list --all -o json --ttl 30000`

Output:
```json
{
  "requestId": "550e8400-e29b-41d4-a716-446655440001",
  "summary": { "total": 3, "online": 1, "stale": 1, "unreachable": 1 },
  "instances": [
    {
      "instanceId": "a1111111-1111-1111-1111-111111111111",
      "pid": 11111,
      "listenAddr": "127.0.0.1:54000",
      "projects": ["/home/alice/project-a"],
      "project": "/home/alice/project-a",
      "brokkctlVersion": "1.1.0",
      "startedAt": 1690000000000,
      "lastSeenMs": 1690001050000,
      "platform": "linux",
      "listenProtocol": "http",
      "status": "online",
      "stale": false,
      "probe": { "reachable": true, "serverVersion": "1.1.0", "latencyMs": 4 },
      "error": null
    },
    {
      "instanceId": "b2222222-2222-2222-2222-222222222222",
      "pid": 22222,
      "listenAddr": "/tmp/brokk-22222.sock",
      "projects": ["/home/alice/project-b"],
      "project": "/home/alice/project-b",
      "brokkctlVersion": "1.0.0",
      "startedAt": 1689990000000,
      "lastSeenMs": 1689999000000,
      "platform": "linux",
      "listenProtocol": "unix",
      "status": "stale",
      "stale": true,
      "probe": { "reachable": false, "latencyMs": 0 },
      "error": null
    },
    {
      "instanceId": "c3333333-3333-3333-3333-333333333333",
      "pid": null,
      "listenAddr": "127.0.0.1:54200",
      "projects": null,
      "project": null,
      "brokkctlVersion": "1.0.0",
      "startedAt": 1689990000000,
      "lastSeenMs": 1689995000000,
      "platform": "linux",
      "listenProtocol": "http",
      "status": "unreachable",
      "stale": true,
      "probe": { "reachable": false, "latencyMs": 0 },
      "error": {
        "code": "TRANSPORT_ERROR",
        "message": "connection refused",
        "details": { "attemptedAddr": "127.0.0.1:54200", "cause": "ECONNREFUSED" }
      }
    }
  ],
  "elapsedMs": 60
}
```

Notes on the example:
- The first entry is current/online (within TTL).
- The second entry is stale by age but probing did not produce a connection error (possibly the instance is paused or removed).
- The third entry is stale and probing produced a transport-level error; it's marked `unreachable` and includes an `error` detailing the probe failure.
- Clients should treat `status == "online"` as suitable for immediate operations. `stale` entries may be re-probed or pruned. `unreachable` entries indicate registry residue and can be pruned using `instances prune` (if appropriate permissions exist).

Implementation hints
- Keep `instances list` cheap by default: avoid network probes unless explicitly requested or when running `--all` with `--probe`.
- Make `--all` the only flag that includes stale/unreachable entries; otherwise scripts will observe only currently-considered-live instances.
- Provide `instances prune` to remove stale/unreachable registry files (guarded by ownership checks).
- Always include `lastSeenMs` in output so callers can apply their own TTL logic.

## Projects commands — specification

This section specifies `brokkctl projects list` and `brokkctl projects open`. These commands allow automation to enumerate projects known to running instances and to request that an instance open a particular project/workspace.

Goals
- Provide a machine-friendly enumeration of projects visible across discovered instances.
- Support deterministic selectors for opening a project by `path` or `projectId`.
- Represent duplicates (same project open in multiple instances) explicitly so callers can choose a target.
- Return structured, actionable errors for common failure modes (not found, already open, permission denied, transport/auth errors).

Common command semantics
- Projects are identified by:
  - `path` — canonical absolute filesystem path (string). Clients SHOULD normalize paths to a platform-canonical form before comparing.
  - `projectId` — an opaque identifier assigned by an instance for an opened project (string). Not all instances may expose `projectId`; when absent `path` is the canonical identity.
- `projects list` aggregates declarations from discovered instances. Each instance's report includes the workspace `path` and optional `projectId` and metadata (name, lastOpenedMs).
- `projects open` requests that an instance open the project at a given `path` (or `projectId` for local-to-instance operations). The command targets one or more instances depending on `--instance`/`--all` flags.

Global flags (inherit from top-level)
- `--format json|text`, `--instance <selector>`, `--all`, `--timeout`, `--request-id`, etc.
- `projects open` specific flags:
  - `--path <abs-path>` — open project at specified absolute path (preferred).
  - `--project-id <id>` — instance-local project id (used for intra-instance actions).
  - `--create-if-missing` — if the instance does not have the project discovered, attempt to create/open it (may fail with permission or not-supported).
  - `--wait <ms>` — wait for the instance to report the project as opened (useful for automation needing synchronous completion).

Note: `projects open` semantics differ when targeting multiple instances. Opening the same path across multiple instances is allowed and is treated as independent operations per instance. Use `--all` to fan-out.

projects list — behavior & schema
- Default: return projects aggregated from non-stale instances only. Use `--all` to include entries from stale instances.
- For each discovered instance, the instance should report zero or more project descriptors:
  - `projectId` (string|null): instance-local identifier for the project.
  - `path` (string): absolute canonical path to the project root.
  - `name` (string|null): optional project display name (e.g., repository name).
  - `lastOpenedMs` (number|null): epoch ms when instance last reported this project active/open.
  - `status` (string): one of `open` or `closed` from the instance's perspective.
  - `readOnly` (boolean, optional): whether the instance opened the project in read-only mode.
  - `instanceId` (string): instance where this descriptor came from.

Output envelope (JSON mode) — `projects list` top-level
```json
{
  "requestId": "uuid",
  "summary": { "totalProjects": 3, "uniquePaths": 2 },
  "projects": [
    {
      "path": "/home/alice/project-a",
      "name": "project-a",
      "instances": [
        {
          "instanceId": "a111...",
          "projectId": "p-123",
          "status": "open",
          "lastOpenedMs": 1690001050000,
          "readOnly": false
        },
        {
          "instanceId": "b222...",
          "projectId": "p-555",
          "status": "open",
          "lastOpenedMs": 1690001000000,
          "readOnly": true
        }
      ]
    },
    {
      "path": "/home/alice/project-b",
      "name": "project-b",
      "instances": [
        {
          "instanceId": "c333...",
          "projectId": null,
          "status": "closed",
          "lastOpenedMs": null
        }
      ]
    }
  ],
  "elapsedMs": 25
}
```

Notes:
- `projects` is grouped by canonical `path` (the aggregation key). This allows callers to see duplicates across instances. For projects reported with different paths that normalize to the same canonical path, implementations SHOULD merge entries under the normalized path.
- `summary.uniquePaths` counts canonical distinct paths after normalization.
- If an instance reports a project but does not expose `projectId`, `projectId` should be null and callers should use `--instance` + `--path` to target that instance for `projects open`/other operations.

Example: `projects list` zero projects
```json
{
  "requestId": "gen",
  "summary": { "totalProjects": 0, "uniquePaths": 0 },
  "projects": [],
  "elapsedMs": 4
}
```

projects open — behavior & per-instance results
- `projects open` is an operational command that may be targeted at:
  - A single instance via `--instance <selector>` (recommended).
  - Multiple instances via `--all` (fan-out; use with care).
  - Auto-selected instance via `--auto-select`.
- The client may pass `--path` or `--project-id`. If both are supplied, `--project-id` is interpreted as an instance-local id and `--path` must match the located project on that instance or the command should error with `INVALID_ARGS`.
- If `--create-if-missing` is set, the instance may attempt to create or register an absent project. If unsupported, the instance returns `PROTOCOL_UNSUPPORTED_FEATURE` or `NOT_FOUND` depending on semantics.

Per-instance result container (projects open)
```json
{
  "instanceId": "a111...",
  "status": "ok",
  "data": {
    "projectId": "p-123",
    "path": "/home/alice/project-a",
    "openedAtMs": 1690002000000
  },
  "error": null,
  "elapsedMs": 120
}
```

Error cases and canonical error codes
- `NOT_FOUND` — requested path/projectId not found on the targeted instance.
  - Example details: `{ "attemptedPath": "...", "reason": "not-in-workspace" }`
- `ALREADY_OPEN` — instance already has the project open in an incompatible mode (e.g., same project open read-only but client requested write).
  - Example details: `{ "currentMode": "read-only", "requestedMode": "read-write" }`
- `PERMISSION_DENIED` — instance was denied access to open path (filesystem permission issues, sandboxing).
  - Example details: `{ "attemptedPath": "...", "osError": "EACCES" }`
- `PROTOCOL_UNSUPPORTED_FEATURE` — instance does not support `--create-if-missing` or other optional features.
- `TRANSPORT_ERROR` / `UNAUTHORIZED` — as in overall transport/security failures.

Fan-out aggregation for `projects open`
- When `--all` is used, return the aggregate envelope described earlier: `summary` with requested/succeeded/failed and `results` array of per-instance containers. Mixed outcomes map to `PARTIAL_SUCCESS` exit code `4`.

Examples

1) Successful open on a single instance
Command:
- `brokkctl projects open --instance a111... --path /home/alice/project-a -o json`

Output:
```json
{
  "requestId": "req-1",
  "results": [
    {
      "instanceId": "a111...",
      "status": "ok",
      "data": {
        "projectId": "p-123",
        "path": "/home/alice/project-a",
        "openedAtMs": 1690002000000
      },
      "error": null,
      "elapsedMs": 120
    }
  ],
  "summary": { "requested": 1, "succeeded": 1, "failed": 0 }
}
```

2) Project not found on targeted instance
Command:
- `brokkctl projects open --instance a111... --path /not/exist -o json`

Output:
```json
{
  "requestId": "req-2",
  "results": [
    {
      "instanceId": "a111...",
      "status": "error",
      "data": null,
      "error": {
        "code": "NOT_FOUND",
        "message": "Path '/not/exist' not found or not a supported workspace root on instance 'a111...'",
        "details": { "attemptedPath": "/not/exist" }
      },
      "elapsedMs": 30
    }
  ],
  "summary": { "requested": 1, "succeeded": 0, "failed": 1 }
}
```

3) Already open (incompatible mode)
Command:
- `brokkctl projects open --instance b222... --path /home/alice/project-a --create-if-missing -o json`

Output:
```json
{
  "requestId": "req-3",
  "results": [
    {
      "instanceId": "b222...",
      "status": "error",
      "data": null,
      "error": {
        "code": "ALREADY_OPEN",
        "message": "Project is already open in read-only mode on this instance.",
        "details": { "currentMode": "read-only", "requestedMode": "read-write" }
      },
      "elapsedMs": 5
    }
  ],
  "summary": { "requested": 1, "succeeded": 0, "failed": 1 }
}
```

4) Fan-out open with mixed outcomes
Command:
- `brokkctl projects open --all --path /shared/repo -o json --best-effort`

Output:
```json
{
  "requestId": "req-4",
  "summary": { "requested": 3, "succeeded": 2, "failed": 1 },
  "results": [
    {
      "instanceId": "a111...",
      "status": "ok",
      "data": { "projectId": "p-123", "path": "/shared/repo", "openedAtMs": 1690003000000 },
      "error": null
    },
    {
      "instanceId": "b222...",
      "status": "ok",
      "data": { "projectId": "p-555", "path": "/shared/repo", "openedAtMs": 1690003000100 },
      "error": null
    },
    {
      "instanceId": "c333...",
      "status": "error",
      "data": null,
      "error": { "code": "PERMISSION_DENIED", "message": "Access denied to '/shared/repo'", "details": {} }
    }
  ],
  "elapsedMs": 410
}
```

Implementation guidance (projects)
- Normalize paths for grouping and comparison. Prefer platform-canonical absolute paths.
- Provide both `path`-first and `projectId`-first flows. When `projectId` is provided, require `--instance` to resolve it deterministically (projectId is instance-local).
- When aggregating `projects list`, group results by normalized `path`. Include the per-instance descriptors under `instances`.
- For `projects open`, prefer single-instance targeting for predictable behavior in scripts. If `--all` is used, make failure policy explicit via `--fail-fast`/`--best-effort`.
- Report clear, machine-friendly error codes (NOT_FOUND, ALREADY_OPEN, PERMISSION_DENIED) and include useful `details` for automation.

## Sessions commands — specification

This section specifies the `sessions active`, `sessions list`, `sessions create`, and `sessions switch` commands. Sessions are first-class automation entities and are commonly required for execution and context operations. The commands below describe required selectors, session identifiers, output schemas, and expected behavior when no active session exists.

Principles
- Sessions are scoped to an instance and to a project opened in that instance (project scope matters for determinism).
- Many session operations require a project selector to disambiguate which project context they apply to. When the project is not supplied and the instance reports multiple open projects, the CLI should require an explicit `--path` or `--project-id`.
- Session identifiers:
  - `sessionId` (string): instance-unique opaque id for a session.
  - `name` (string, optional): human-friendly session name; not guaranteed unique across instances.
- `--instance` is required for any session operation that uses `sessionId` unless `--all` is explicitly used (fan-out cases require per-instance session ids or names with instance context).

Global flags (inherit)
- `--format json|text`, `--instance <selector>`, `--all`, `--timeout`, `--request-id`, etc.
- `sessions` command specific flags:
  - `--path <abs-path>` — project path to scope session operations (preferred).
  - `--project-id <id>` — instance-local project id to scope session operations.
  - `--session-id <id>` — target a specific session by id.
  - `--name <name>` — for create or switch by name (may be ambiguous; prefer `--session-id`).
  - `--create-if-missing` — create session when switching or selecting if not present (behavior depends on server capability).

Behavioral conventions
- Deterministic scoping:
  - If `--instance` is omitted and multiple non-stale instances match discovery, fail with `USER_ERROR` and require `--instance`, `--all`, or `--auto-select`.
  - If project scope is ambiguous (multiple open projects in the chosen instance) and `--path`/`--project-id` is not provided, fail with `USER_ERROR` and instruct to provide `--path` or `--project-id`.
- Fan-out rules:
  - `--all` may be used to perform the command across all non-stale instances. Results MUST be aggregated as described earlier.
  - For multi-instance `sessions switch` with `--all`, the client must specify session identifiers per instance (e.g., via a mapping file) or rely on `name` matching; ambiguity may result in per-instance `NOT_FOUND` or `AMBIGUOUS` errors.

### sessions active

Purpose
- Return the currently active session for the selected instance/project (if any). Useful for tooling that wants to target the presently active workspace session.

Inputs
- `--instance <selector>` (optional, auto-selected per rules).
- `--path <abs-path>` or `--project-id <id>` (required when the instance has multiple open projects).
- `--request-id <uuid>`, `--timeout`, `--auth-token`, `--format`.

Behavior
- If an active session exists for the specified project on the instance, return a single per-instance result with `status: "ok"` and `data` containing the session descriptor.
- If no active session exists, return `status: "ok"` with `data: null` and an explicit `active: false` or return `status: "error"` with code `NOT_FOUND` depending on invocation semantics:
  - Preferred: `status: "ok"` and `data: { "active": false, "message": "No active session" }`. This is more automation-friendly (no need to treat absence as an error).
  - If caller used `--require-active`, return `status: "error"` code `NOT_FOUND` and message indicating missing active session.

Output schema (JSON mode)
Per-instance success envelope when active:
```json
{
  "instanceId": "a111...",
  "status": "ok",
  "data": {
    "sessionId": "s-123",
    "name": "interactive",
    "createdAtMs": 1690002000000,
    "lastActiveMs": 1690003000000,
    "project": { "path": "/home/alice/project-a", "projectId": "p-123" },
    "readOnly": false
  },
  "error": null,
  "elapsedMs": 4
}
```

When no active session:
```json
{
  "instanceId": "a111...",
  "status": "ok",
  "data": { "active": false, "message": "No active session for project '/home/alice/project-a'" },
  "error": null,
  "elapsedMs": 2
}
```

If `--require-active` is used:
```json
{
  "instanceId": "a111...",
  "status": "error",
  "data": null,
  "error": { "code": "NOT_FOUND", "message": "No active session for project '/home/alice/project-a'" },
  "elapsedMs": 2
}
```

Exit codes:
- No active session in default mode: overall exit `0` (success) because the request succeeded, but `data.active` is false.
- With `--require-active`: exit `1` (USER_ERROR) or `NOT_FOUND` semantic mapped per project conventions.

### sessions list

Purpose
- List sessions known to an instance for a given project scope. Useful for enumerating saved sessions, autosaved snapshots, or historical session artifacts.

Inputs
- `--instance <selector>` (recommended for determinism).
- `--path <abs-path>` or `--project-id <id>` (project selector required unless the instance exposes only one project).
- `--limit <n>` (optional): limit results.
- `--request-id`, `--timeout`, `--format`.

Behavior
- Return all sessions for the specified project reported by the instance. When `--all` is used, aggregate across instances and group by normalized path.
- Each session descriptor should include `sessionId`, `name`, `createdAtMs`, `lastActiveMs`, `sizeBytes` (optional), `tags` (optional), and a boolean `isActive` (true if the session is currently active).

Output envelope (JSON mode)
Single-instance response:
```json
{
  "requestId": "req-10",
  "summary": { "total": 2 },
  "sessions": [
    {
      "sessionId": "s-123",
      "name": "interactive",
      "createdAtMs": 1690002000000,
      "lastActiveMs": 1690003000000,
      "isActive": true,
      "tags": ["work-in-progress"]
    },
    {
      "sessionId": "s-122",
      "name": "pre-merge",
      "createdAtMs": 1689000000000,
      "lastActiveMs": 1689001000000,
      "isActive": false
    }
  ],
  "elapsedMs": 8
}
```

Multi-instance `--all` aggregated response:
```json
{
  "requestId": "req-11",
  "summary": { "total": 3 },
  "sessions": [
    {
      "instanceId": "a111...",
      "sessionId": "s-123",
      "name": "interactive",
      "createdAtMs": 1690002000000,
      "lastActiveMs": 1690003000000,
      "isActive": true
    },
    {
      "instanceId": "b222...",
      "sessionId": "s-999",
      "name": "interactive",
      "createdAtMs": 1690005000000,
      "lastActiveMs": 1690005005000,
      "isActive": true
    },
    {
      "instanceId": "a111...",
      "sessionId": "s-122",
      "name": "pre-merge",
      "createdAtMs": 1689000000000,
      "lastActiveMs": 1689001000000,
      "isActive": false
    }
  ],
  "elapsedMs": 40
}
```

Edge cases:
- If no sessions exist for the project, return an empty `sessions` array and `summary.total == 0` (exit 0).

### sessions create

Purpose
- Create a new session for a project on an instance. Sessions may be ephemeral or persisted depending on server capabilities.

Inputs
- `--instance <selector>` (recommended/deterministic).
- `--path <abs-path>` or `--project-id <id>` (project scope required).
- `--name <name>` (optional): session display name.
- `--tags <comma-separated>` (optional): metadata tags.
- `--request-id`, `--timeout`, `--auth-token`, `--wait <ms>` (optional): wait for session to be fully initialized.

Behavior
- The instance validates project scope and creates a session. On success, return per-instance result with `status: "ok"` and `data` containing the created session descriptor (including `sessionId`).
- If the requested project is not found, return `NOT_FOUND`.
- If a session with the same name already exists and the server rejects duplicates, return `ALREADY_EXISTS` with helpful `details`.

Per-instance result schema (success):
```json
{
  "instanceId": "a111...",
  "status": "ok",
  "data": {
    "sessionId": "s-200",
    "name": "feature-x",
    "createdAtMs": 1690004000000,
    "isActive": true,
    "project": { "path": "/home/alice/project-a", "projectId": "p-123" }
  },
  "error": null,
  "elapsedMs": 120
}
```

Error examples:
- `NOT_FOUND` — project does not exist on the instance.
- `ALREADY_EXISTS` — session with the given name exists and duplicate creation is disallowed.
- `PERMISSION_DENIED` — insufficient permission to create session (sandboxed environment).

Exit code:
- On success: `0`.
- On failure: appropriate non-zero mapped code (USER_ERROR, TRANSPORT_ERROR, etc.) or `4` for mixed fan-out results.

### sessions switch

Purpose
- Switch the active session for a project on an instance. This operation sets which session subsequent execution and context additions target.

Inputs
- `--instance <selector>` (recommended).
- `--path <abs-path>` or `--project-id <id>` (project scope required when ambiguous).
- Either `--session-id <id>` (preferred) or `--name <name>` (less deterministic).
- `--create-if-missing` (optional): if the requested session name does not exist, create it (server may refuse with `PROTOCOL_UNSUPPORTED_FEATURE`).
- `--wait <ms>` (optional): wait until the server reports the session as active.
- `--request-id`, `--timeout`, `--auth-token`.

Behavior
- If the session exists, the server activates it and returns `status: "ok"` with `data` containing the now-active session descriptor.
- If the session does not exist:
  - If `--create-if-missing` is set and supported: create and activate a new session (return `ok` with data).
  - Otherwise return `NOT_FOUND`.
- If switching would be a no-op (already active), return `status: "ok"` with `data` indicating `alreadyActive: true` and current session descriptor.
- For multi-instance `--all`, apply per-instance rules; ambiguous `--name` matches may yield per-instance `AMBIGUOUS` or `NOT_FOUND` errors.

Per-instance success response:
```json
{
  "instanceId": "a111...",
  "status": "ok",
  "data": {
    "sessionId": "s-123",
    "name": "interactive",
    "activatedAtMs": 1690005000000,
    "previousSessionId": "s-122",
    "project": { "path": "/home/alice/project-a", "projectId": "p-123" },
    "alreadyActive": false
  },
  "error": null,
  "elapsedMs": 30
}
```

No-op response when already active:
```json
{
  "instanceId": "a111...",
  "status": "ok",
  "data": { "alreadyActive": true, "sessionId": "s-123", "name": "interactive" },
  "error": null,
  "elapsedMs": 1
}
```

Error example when session not found:
```json
{
  "instanceId": "a111...",
  "status": "error",
  "data": null,
  "error": { "code": "NOT_FOUND", "message": "Session 'feature-x' not found for project '/home/alice/project-a'" },
  "elapsedMs": 5
}
```

Exit codes:
- Success: `0`.
- `NOT_FOUND` without `--create-if-missing`: `1` (USER_ERROR) or mapped `NOT_FOUND`.
- Mixed fan-out results: `4` (PARTIAL_SUCCESS) and include aggregated `summary`.

Implementation notes (sessions)
- Require explicit project scoping to avoid ambiguous cross-project session activation.
- Prefer `sessionId` for precise operations; accept `name` for convenience but warn about ambiguity in documentation and interactive prompts.
- Sessions should be lightweight to create (fast), and servers should instrument `createdAtMs` and `lastActiveMs` for automation usage.
- Always include `project` scoping in returned session descriptors so callers can correlate a session to a canonical project path and optional `projectId`.

## Context commands — specification

Purpose
- Manage session-scoped or project-scoped contextual data that seeds LLM reasoning: files, class/method fragments, free-form text, or other content artifacts. These commands let automation enumerate, add, and remove context entries used by executions.

Common flags / selectors
- Global flags apply (`--format`, `--instance`, `--all`, `--timeout`, `--request-id`, etc.).
- Context-specific selectors:
  - `--path <abs-path>` — canonical project path to scope the operation (required when the instance has multiple open projects).
  - `--project-id <id>` — instance-local project id to scope operations (preferred when available).
  - `--session-id <id>` — session to which the context will be added / from which it will be listed or removed. If omitted, commands act against the active session for the selected project (subject to `sessions active` rules).
  - `--scope <session|job|global>` (optional) — explicit scope hint. Default: `session`.
- Addressing files / content:
  - For file-backed context, address files by `relativePath` (string) relative to the project root. Examples: `src/main/java/com/acme/Foo.java`, `README.md`.
  - For inline/free-text context, supply `--text` or `--stdin` or `--file @/absolute/path/to/local/file` (client-side convenience; server receives content in payload).
  - Optional `--id <id>`: let the client supply a stable id for the new context entry (server may reject on collision). Servers MUST return assigned `contextId` when not supplied.
  - Optional `--metadata` (JSON): free-form object for tags, language, or hinting (e.g., `{ "language": "java", "type": "class" }`).
  - Optional `--line-range start:end` (e.g., `10:50`) or `--char-range start:end` to add a snippet from a file rather than whole file (server may respond with `PROTOCOL_UNSUPPORTED_FEATURE` if unsupported).

Design principles
- Keep `context list` cheap; avoid retrieving full file contents unless requested.
- Use `relativePath` for file identity when possible; use `contextId` for stable addressing of added entries.
- Server responses should include both `contextId` and `relativePath` (when applicable) so callers can correlate entries added now vs existing library content.

Commands

1) `context list`

Purpose
- Enumerate context entries visible to the selected project + session scope.

Inputs / Flags
- `--format json|text`
- `--instance`, `--path`/`--project-id`, `--session-id` or active session semantics
- `--type <file|text|class|method|diff|all>` (optional) to filter by kind
- `--limit <n>`, `--offset <n>` for paging (optional)
- `--request-id`, `--timeout`

Behavior
- Return entries scoped to the resolved project and session (or global scope when `--scope global`).
- By default return metadata only (no full content). Support an optional `--include-content` to return contents or snippets.
- Normalize `relativePath` output to platform-canonical form.

Output schema (JSON mode)
Top-level:
```json
{
  "requestId": "uuid",
  "summary": { "total": 3 },
  "context": [
    {
      "contextId": "ctx-1",
      "type": "file",
      "relativePath": "src/main/java/com/acme/Foo.java",
      "addedBy": "user",
      "addedAtMs": 1690001000000,
      "sizeBytes": 1234,
      "snippet": "public class Foo { ... }",
      "sessionId": "s-123",
      "tags": ["important"],
      "metadata": { "language": "java" }
    },
    {
      "contextId": "ctx-2",
      "type": "text",
      "relativePath": null,
      "addedBy": "user",
      "addedAtMs": 1690002000000,
      "sizeBytes": 234,
      "snippet": "Design note: We should...",
      "sessionId": "s-123",
      "tags": [],
      "metadata": { "source": "paste" }
    }
  ],
  "elapsedMs": 12
}
```

Field notes:
- `contextId` (string): stable server-assigned id for the context entry.
- `type` (string): one of `file`, `text`, `class`, `method`, `diff`, etc.
- `relativePath` (string|null): path relative to project root when applicable.
- `snippet` (string|null): short excerpt for display; controlled by server and may be truncated.
- `sessionId` (string|null): session-scoped id; null for global scope.
- `metadata` (object|null): server/caller provided metadata.

2) `context add`

Purpose
- Add one or more context entries to a session/project. Commonly used to seed files, snippets, or textual hints before submitting jobs.

Inputs / Flags
- `--instance`, `--path`/`--project-id`, `--session-id` (or use active session)
- One or more content sources:
  - `--file <relativePath>` — instruct server to read the file contents from the project workspace (preferred where server has access).
  - `--stdin` and `--text "<content>"` — inline text provided by the client.
  - `--from <local-file>` — client uploads a local file (transport detail).
- `--id <id>` (optional) — desired context id (server may reject duplicates).
- `--overwrite` (optional) — when adding an entry whose `relativePath` already exists, overwrite server-side content. Default: do not overwrite; return `ALREADY_EXISTS`.
- `--type <file|text|class|method|diff>` (optional)
- `--metadata` (optional)
- `--request-id`, `--timeout`

Behavior
- The server attempts to add each provided entry; operations are per-entry and reported individually. For file-based adds (`--file`), the server reads content at that path inside the project workspace; if the file is not present or not readable return `NOT_FOUND` or `PERMISSION_DENIED`.
- When `--overwrite` is not specified and a `relativePath` already exists as context for the same session/scope, return `ALREADY_EXISTS` for that entry.
- If the content is identical to an existing entry (bytewise equality or canonicalized equivalence), treat as idempotent no-op and return `status: "ok"` with `idempotent: true` (see Idempotency section).

Per-instance result container (context add)
```json
{
  "requestId": "req-ctx-add-1",
  "summary": { "requested": 2, "succeeded": 1, "failed": 1 },
  "results": [
    {
      "instanceId": "a111...",
      "status": "ok",
      "data": {
        "contextId": "ctx-100",
        "relativePath": "src/main/java/com/acme/Foo.java",
        "addedAtMs": 1690004000000,
        "idempotent": false
      },
      "error": null,
      "elapsedMs": 45
    },
    {
      "instanceId": "a111...",
      "status": "error",
      "data": null,
      "error": {
        "code": "ALREADY_EXISTS",
        "message": "Context entry for 'src/main/java/com/acme/Foo.java' already exists (use --overwrite to replace).",
        "details": { "existingContextId": "ctx-77" }
      },
      "elapsedMs": 5
    }
  ],
  "elapsedMs": 60
}
```

3) `context remove`

Purpose
- Remove one or more context entries from a session/project. Useful for cleanup or replacing stale content.

Inputs / Flags
- `--instance`, `--path`/`--project-id`, `--session-id` (or active session)
- Target addressing (one of):
  - `--context-id <id>` — remove by server-assigned id (recommended).
  - `--file <relativePath>` — remove by relative path.
  - `--all` — remove all context entries in the selected session/scope (dangerous; requires explicit opt-in).
- `--require-exists` (optional): cause removal to fail if an addressed entry does not exist. Default behavior: idempotent success on missing entries (see Idempotency).
- `--request-id`, `--timeout`

Per-instance result container (context remove)
```json
{
  "requestId": "req-ctx-rm-1",
  "summary": { "requested": 2, "succeeded": 2, "failed": 0 },
  "results": [
    {
      "instanceId": "a111...",
      "status": "ok",
      "data": {
        "removed": [
          { "contextId": "ctx-100", "relativePath": "src/main/java/com/acme/Foo.java" }
        ],
        "skipped": []
      },
      "error": null,
      "elapsedMs": 30
    },
    {
      "instanceId": "a111...",
      "status": "ok",
      "data": {
        "removed": [],
        "skipped": [
          { "query": "src/main/java/com/acme/Missing.java", "reason": "not-found" }
        ]
      },
      "error": null,
      "elapsedMs": 6
    }
  ],
  "elapsedMs": 40
}
```

Output notes:
- `removed` is an array of successful deletions with `contextId` and `relativePath` where known.
- `skipped` is an array of requested targets that were not present and therefore skipped (idempotent path). When `--require-exists` is used these would be reported as per-entry errors instead.

Idempotency semantics (clarified)
- Add:
  - Adding an entry with the same `relativePath` and identical content as an existing entry should be treated as a no-op and return success with `idempotent: true`.
  - Adding with same `relativePath` but different content without `--overwrite` returns `ALREADY_EXISTS`.
  - With `--overwrite`, server replaces existing content and returns success with `idempotent: false` and the new `contextId`/`revision` (if revisions are supported).
- Remove:
  - Removing a non-existent `contextId` or `relativePath` is a no-op and should return success by default (idempotent), listing the target in `skipped`. If caller passes `--require-exists`, server returns `NOT_FOUND` for that target instead.
- List:
  - Purely observational; repeated calls produce stable metadata unless the server's state changes.

Error codes (relevant)
- `INVALID_ARGS` — bad flags or mutually-exclusive options.
- `NOT_FOUND` — when `--require-exists` is set and target is missing, or `--session-id`/`--project-id` point to nothing.
- `ALREADY_EXISTS` — add attempted without `--overwrite` against existing `relativePath`.
- `PERMISSION_DENIED` — server cannot read the workspace file or lacks permission to mutate session-scoped context.
- `PROTOCOL_UNSUPPORTED_FEATURE` — server does not support requested flags (e.g., `--line-range`).
- `TRANSPORT_ERROR` / `UNAUTHORIZED` — as previously defined.

Examples

1) Add local file by relative path (single-instance)
Command:
- `brokkctl context add --path /home/alice/repo --session-id s-123 --file src/main/java/com/acme/Foo.java -o json`

Response (simplified single-instance):
```json
{
  "requestId": "req-ctx-add-1",
  "results": [
    {
      "instanceId": "a111...",
      "status": "ok",
      "data": {
        "contextId": "ctx-100",
        "relativePath": "src/main/java/com/acme/Foo.java",
        "addedAtMs": 1690004000000,
        "idempotent": false
      },
      "error": null
    }
  ],
  "summary": { "requested": 1, "succeeded": 1, "failed": 0 }
}
```

2) Remove by `contextId` with idempotent semantics
Command:
- `brokkctl context remove --path /home/alice/repo --session-id s-123 --context-id ctx-100 -o json`

Response:
```json
{
  "requestId": "req-ctx-rm-1",
  "results": [
    {
      "instanceId": "a111...",
      "status": "ok",
      "data": { "removed": [{ "contextId": "ctx-100", "relativePath": "src/main/java/com/acme/Foo.java" }], "skipped": [] },
      "error": null
    }
  ],
  "summary": { "requested": 1, "succeeded": 1, "failed": 0 }
}
```

Implementation hints
- Prefer `contextId` for long-lived automation; allow `relativePath` for convenience when the caller and server share the same workspace layout.
- Servers should compute and expose a lightweight `digest` (e.g., SHA-256) or `revision` for content entries to make idempotency checks cheap for clients.
- For large content, avoid returning full file contents in `context list` by default; offer `--include-content` with explicit opt-in.
- When supporting multi-instance fan-out, follow the established per-instance `results` + `summary` envelope and map mixed outcomes to `PARTIAL_SUCCESS` exit code `4`.

## Execution commands — specification

This section covers one-off executions (`exec`) and task-list execution (`taskrun`). PLAN and LUTZ differ from ASK and CODE in that they produce (and may later consume) a session task list, so the CLI also exposes task list CRUD (`tasks ...`).

Purpose
- Submit, monitor, and stop executions (jobs) on one or more Brokk instances. Support multiple logical modes and both stream-first (NDJSON) and pollable APIs so automation can either follow live output or fetch events after the fact.

Commands (conceptual)
One-off executions:
- `brokkctl exec start --mode <ask|code|plan|lutz> --session-id <id> --task "<text>" [--model-overrides ...] [--request-id <uuid>] [-o json|ndjson] [--follow]`
- `brokkctl exec stop --job <jobId> [--graceful|--immediate] [--request-id <uuid>] [-o json]`

Task list management (CRUD):
- `brokkctl tasks get [--session-id <id>]`
- `brokkctl tasks set --file <tasks.json> [--session-id <id>] [--replace]`
- `brokkctl tasks add --title "<text>" [--after <taskId>] [--session-id <id>]`
- `brokkctl tasks update --task-id <taskId> [--title "..."] [--status todo|doing|done|blocked] [--notes "..."]`
- `brokkctl tasks remove --task-id <taskId>`
- `brokkctl tasks clear [--confirm]`

Task list execution control (service-like, per project):
- `brokkctl taskrun start [--session-id <id>] [--from-task <taskId>] [--request-id <uuid>] [-o json|ndjson] [--follow]`
- `brokkctl taskrun stop [--graceful|--immediate] [--request-id <uuid>] [-o json]`
- `brokkctl taskrun status [-o json]`

Supported modes
- `ask` — read-only. Takes text instructions and runs the LLM using the current session context. Does not modify files.
- `code` — read/write. Takes text instructions and runs the LLM using the current session context. May modify files to complete the task (patches/diffs).
- `plan` — read-only. Takes text instructions, performs an agentic search over the project sources, adds appropriate files to the session context, and creates or updates the session task list. Does not modify files. The primary output artifact is the task list.
- `lutz` — plan + run. Same as `plan`, but automatically begins executing the resulting task list in order when planning completes.
Clients MUST treat mode names as opaque capability hints for unknown/extended modes.

Common flags / selectors
- `--instance <selector>` — target a single instance (see selection rules).
- `--all` — fan-out to all non-stale instances (aggregate results).
- `--session-id <id>` or scoped `--path/--project-id` — required when session/project scoping is needed.
- `--mode <ask|plan|code|lutz>` — required for `exec start`.
- `--task "<text>"` — task prompt / user input describing what to do. See Request Shape below.
- `--model-overrides` — optional JSON or flagized spec that can include per-role model hints (see below).
- `--follow` — stream events (NDJSON). Without `--follow` a pollable/one-shot response is returned (JSON).
- `--request-id <uuid>` — client-supplied correlation id; generated by client if omitted.
- `--timeout <ms>` — overall timeout for discovery and per-request network ops.
- `--fail-fast` / `--best-effort` — fan-out failure policy.

Exec start — request shape (client → instance)
Canonical JSON client request envelope:

{
  "requestId": "550e8400-e29b-41d4-a716-446655440000",
  "createdAtMs": 1690000000000,
  "command": "execution.start",
  "protocolVersion": "1.0.0",
  "payload": {
    "mode": "plan",                       // "ask" | "code" | "plan" | "lutz"
    "sessionId": "s-123",                 // if provided and differs from the current session for the project, the instance will switch sessions first
    "task": "Refactor module X to reduce duplication and add tests.",
    "modelOverrides": {                   // optional model overrides (instances may ignore unknown keys)
      "planner": "gpt-4o-mini",
      "composer": "gpt-4o",
      "editor": "gpt-4o"
    },
    "runOptions": {
      "timeoutMs": 120000,
      "maxTokens": 4096,
      "preserveHistory": true
    },
    "meta": { "tag": "ci-run", "priority": "low" }
  }
}

Exec start — immediate response (non-streaming or initial handshake)
- On success the instance returns a canonical per-instance result container with `status: "ok"` and `data` containing at minimum:
  - `jobId` (string) — server-assigned job id for this execution
  - `mode` (string)
  - `startedAtMs` (number)
  - `cursor` (string|null) — opaque token pointing to the stream position immediately after any pre-start events
  - `followUrl` (string|null) — optional direct URL to follow stream

Mode-specific output notes:
- `ask`: output is assistant text/events only; no filesystem changes.
- `code`: output may include patch/diff artifacts and file edit events.
- `plan`: output MUST include an updated session task list artifact (either inline in the terminal event payload, or as a `taskListRef` pointing to retrievable task list content).
- `lutz`: output includes the same task list artifact as `plan`, plus subsequent task execution events as the task list runs.
- If `--follow` was requested and the server supports streaming, the HTTP response may be an NDJSON stream (see Streaming below). In that case the initial NDJSON lines SHOULD include a `job.started` event and subsequent events for job progress/output.

Exec start — poll-driven mode
- If the client does not request `--follow` or the server does not support streaming, clients poll:
  - `GET /v1/jobs/{jobId}/events?cursor=<cursor>&limit=<n>`
  - Or list recent events via `history get` semantics scoped to the job/session.
- Polling responses follow the `history get` envelope in this spec (events array + nextCursor).

Streaming (NDJSON) mode
- When `--follow` is used the server SHOULD stream NDJSON lines where each line is a self-contained JSON event (see Event Stream JSON Schema below). The first line SHOULD be an event with `eventType: "job.started"` and include `jobId` and `mode`.
- The server SHOULD periodically emit heartbeat lines (control lines) to keep the connection alive in idle periods, for example:
  { "requestId":"...", "type":"heartbeat", "nowMs":1690000005000 }
- If an instance encounters an error mid-stream for this job, emit an error envelope (see error shape below) and either continue (best-effort) or close the stream depending on server policy and whether the error is fatal.

Event Stream JSON Schema (NDJSON / event envelopes)
Each streamed event (or polled history event) SHOULD follow this canonical envelope. The shape purposefully mirrors the history/event shapes in this spec without coupling to internal classes.

{
  "requestId": "550e8400-e29b-41d4-a716-446655440000", // client's original requestId when available
  "instanceId": "a1111111-1111-1111-1111-111111111111",
  "jobId": "j-42",
  "sequence": 105,                       // monotonically increasing per-instance per-job (or per-session if job-less)
  "createdAtMs": 1690006003000,
  "eventType": "job.started|job.stdout|job.stderr|job.progress|job.event|job.complete|job.error",
  "author": "assistant|system|user",     // optional, when applicable
  "text": "Partial textual output chunk (may be null)",
  "payload": {                           // structured payload specific to eventType
    // Examples:
    // job.started -> { "mode":"plan", "serverVersion":"1.1.0" }
    // job.stdout -> { "chunk":"text", "isFinal":false }
    // job.progress -> { "phase":"planning", "percent":42.5 }
    // job.event -> { "type":"patch.applied", "details": { "file":"x","hunks":1 } }
    // job.complete -> { "status":"success|failed|cancelled", "result": { /* job-specific */ } }
    // job.error -> { "code":"INTERNAL_ERROR", "message":"...", "details": {...} }
  },
  "tags": ["stdout","partial"],         // optional tags
  "cursor": "inst:a111:job:j-42:seq:105" // opaque resume token for this instance/job
}

EventType semantics
- job.started — emitted when the execution is accepted and begins. Payload includes `mode` and optional server hints.
- job.stdout / job.stderr — textual output streams emitted by the execution.
- job.progress — structured progress updates.
- job.event — structured events:
  - `plan.taskList.updated` when PLAN/LUTZ updates the session task list.
  - `code.patch.applied` when CODE applies an edit.
  - `taskrun.task.started` / `taskrun.task.completed` when a task list run advances through tasks.
- job.complete — terminal event. Payload must include `status` (`success`|`failed`|`cancelled`) and MAY include:
  - `taskList` (inline) or `taskListRef` (reference) for PLAN/LUTZ
  - `diffRef` / `patchSummary` for CODE
- job.error — unrecoverable error; includes canonical error object.

Polling / History compatibility
- All streamed events MUST also be representable via `history get`/paging APIs (cursor-friendly), so clients choosing to poll can obtain the same semantic events. Events returned via polling must include the `cursor` so clients can resume.

Exec stop — semantics and flags
- `--graceful` (default when unspecified): request polite cancellation allowing the current internal phase to finish or checkpoint. Servers SHOULD attempt to produce a `job.complete` with `status: "cancelled"` and any partial results that are safe to emit.
- `--immediate`: request immediate abort. Best-effort; may not be supported for all modes.
- `--force` (rare): stronger immediate semantics; servers may refuse unless explicitly authorized.

Note: Stopping a one-off execution (`ask`, `code`, `plan`, `lutz`) addresses a specific `jobId`. Stopping a task list run (`taskrun stop`) addresses the currently running task list execution for the project (if any).

Exec stop — request shape (client → instance)
{
  "requestId": "550e8400-e29b-41d4-a716-446655440001",
  "createdAtMs": 1690000100000,
  "command": "execution.stop",
  "payload": {
    "jobId": "j-42",
    "mode": "graceful"  // "graceful" | "immediate"
  }
}

Exec stop — response shape
- Per-instance result container with:
  - `status: "ok"` and `data` containing `{ "jobId":"j-42", "stopped": true, "stoppedAtMs": 1690000105000, "previousStatus": "running" }`
  - Or `status: "error"` with a canonical error object (e.g., `NOT_FOUND`, `ALREADY_COMPLETED`, `PERMISSION_DENIED`, `TRANSPORT_ERROR`).
- If stop is requested while streaming follow is active, the stream SHOULD emit a final `job.complete` or `job.error` event and then the server may close the connection.

Idempotency and races
- `exec stop` should be idempotent: stopping an already-stopped job returns success with `stopped:false` or explicit `ALREADY_COMPLETED` error depending on semantics.
- Project-level single execution rule:
  - Each project may have at most one running execution at a time.
  - If a start request targets a session while another session is currently executing for the same project, the server MUST reject with `BUSY` (or `ALREADY_RUNNING`) and include details describing the running execution (jobId, mode, sessionId if permitted).
- Session switching behavior for project-scoped execution control:
  - For `execution.start` and `taskrun start/stop`, if `payload.sessionId` is provided and differs from the current session for the project, the instance switches the UI/current session first, then performs the requested action.
  - For `taskrun status`, if the requested session is not the current session for the project, the status is deterministically `stopped` (because only the current session can be executing).

Model overrides and capability negotiation
- Clients may pass `modelOverrides` on `exec start`. Servers declare supported override keys via `supportedCapabilities` on `ctl-info` (e.g., `"execution.modelOverrides": ["planner","editor"]`). If an unsupported override is requested, the server responds with `PROTOCOL_UNSUPPORTED_FEATURE` with useful details.
- When `Brokk-CTL-Version` mismatches in MINOR the server may return `PROTOCOL_UNSUPPORTED_FEATURE` describing missing execution features.

Security and cancellation authority
- Servers MAY restrict who can stop certain jobs (e.g., only the submitting session or users with elevated privileges). `exec stop` failures due to permission must return `PERMISSION_DENIED`.

Examples (NDJSON stream excerpt for a `plan` job)
Line 1:
{ "requestId":"req-1","instanceId":"a111...","jobId":"j-42","sequence":1,"createdAtMs":1690006000000,"eventType":"job.started","payload":{"mode":"plan","serverVersion":"1.1.0"},"cursor":"inst:a111:job:j-42:seq:1" }

Line 2 (progress):
{ "requestId":"req-1","instanceId":"a111...","jobId":"j-42","sequence":2,"createdAtMs":1690006001000,"eventType":"job.progress","payload":{"phase":"planning","percent":12.0},"cursor":"inst:a111:job:j-42:seq:2" }

Line 3 (stdout chunk):
{ "requestId":"req-1","instanceId":"a111...","jobId":"j-42","sequence":3,"createdAtMs":1690006001500,"eventType":"job.stdout","text":"Planner: considering candidates...","payload":{"isFinal":false},"cursor":"inst:a111:job:j-42:seq:3" }

Line 4 (job complete):
{ "requestId":"req-1","instanceId":"a111...","jobId":"j-42","sequence":50,"createdAtMs":1690006015000,"eventType":"job.complete","payload":{"status":"success","result":{"summary":"Applied 3 patches","diffRef":"ref://diff/123"}},"cursor":"inst:a111:job:j-42:seq:50" }

Operational notes
- Prefer NDJSON for streaming/live follow because it is line-delimited and easy for CLI tools to consume (jq, tail -f).
- Ensure event envelopes are small and self-contained; include `cursor` on every event to enable per-instance resume semantics.
- `exec start` should return quickly with `jobId` even for long-running jobs so clients can concurrently subscribe to events or poll status.
- Servers should document per-mode cancellation semantics in `supportedCapabilities` so clients can make informed stop requests.

Compatibility with existing history/state APIs
- Execution events (including task list updates and task list run progress) MUST be emit-able into the `history` subsystem so `history get`/`history tail` can return the same events as the live stream.
- Servers that cannot or choose not to store full history should document this (e.g., `ephemeralStreamsOnly` capability) and clearly expose cursors that are only valid for live connections.

## Task list commands — specification

Purpose
- Provide CRUD operations for the current session task list, since PLAN and LUTZ create or update it and LUTZ/task execution consumes it.

Task list model (canonical)
- A task list is an ordered list of tasks for a session.
- Each task MUST have a stable `taskId` (string) for reliable automation edits.
- Minimal task shape:

```json
{
  "taskId": "t-1",
  "title": "Add unit tests for Foo",
  "status": "todo",
  "notes": "Focus on edge cases",
  "createdAtMs": 1690000000000,
  "updatedAtMs": 1690000100000
}
```

Common selectors
- `--instance <selector>`
- `--path <abs-path>` or `--project-id <id>` (project scope)
- `--session-id <id>` (optional; if omitted, operate on the active session for the project)

### tasks get

- Returns the task list for the resolved session.

Response (JSON):
```json
{
  "requestId": "req-tasks-1",
  "results": [
    {
      "instanceId": "a111...",
      "status": "ok",
      "data": {
        "sessionId": "s-123",
        "tasks": [
          { "taskId": "t-1", "title": "Inspect Foo", "status": "done", "notes": null, "createdAtMs": 1690000000000, "updatedAtMs": 1690000050000 },
          { "taskId": "t-2", "title": "Refactor Bar", "status": "todo", "notes": null, "createdAtMs": 1690000060000, "updatedAtMs": 1690000060000 }
        ]
      },
      "error": null
    }
  ],
  "summary": { "requested": 1, "succeeded": 1, "failed": 0 }
}
```

### tasks set

- Replaces the task list for the resolved session (authoritative overwrite). Servers MAY support partial patch/update, but replace is canonical for automation.

Request payload:
```json
{
  "command": "tasks.set",
  "payload": {
    "sessionId": "s-123",
    "replace": true,
    "tasks": [
      { "taskId": "t-1", "title": "Do X", "status": "todo", "notes": null }
    ]
  }
}
```

Errors
- `NOT_FOUND` if session not found.
- `BUSY` if the project is currently executing a task list (servers may require stopping first).
- `INVALID_ARGS` if task ids are duplicated or invalid.

### tasks add / update / remove / clear

- `tasks add` appends or inserts a task.
- `tasks update` edits fields of a task.
- `tasks remove` deletes a task by `taskId`.
- `tasks clear` removes all tasks (requires explicit confirmation in CLI UX).

All return per-instance result containers and use canonical error codes (`NOT_FOUND`, `BUSY`, `INVALID_ARGS`, `PERMISSION_DENIED`).

## Task list execution control — specification (`taskrun`)

Purpose
- Start/stop/status for executing the current session task list for a project. This behaves like a single service per project: only one task run may be active for a project at a time.

### taskrun start

Behavior
- Resolves the project and session. If a `--session-id` is provided and differs from the project's current session, the instance switches the current session first (reflected in desktop UI), then starts executing that session task list.
- If another session is currently executing for the same project, return `BUSY`.

Response data (success):
```json
{
  "taskRunId": "tr-1",
  "jobId": "j-42",
  "sessionId": "s-123",
  "startedAtMs": 1690006000000
}
```

Streaming
- When `--follow` is used, stream NDJSON events using the same event envelope as executions, with taskrun events under `job.event` payload types (e.g., `taskrun.task.started`).

### taskrun stop

Behavior
- Stops the currently running task run for the project. If `--session-id` is provided and differs from the current session, the instance switches first, then attempts to stop (typically resulting in `stopped:false` unless that session is the one running).

### taskrun status

Behavior
- Returns status for the project's current session task run.
- If the requested session is not the current session for the project, status is deterministically `stopped`.

Status data shape:
```json
{
  "sessionId": "s-123",
  "state": "running",
  "jobId": "j-42",
  "startedAtMs": 1690006000000,
  "currentTaskId": "t-2",
  "cancellable": true
}
```

Errors
- `BUSY` when attempting `taskrun start` while already running.
- `NOT_FOUND` if project/session not found (unless using the non-failing "inactive means stopped" semantics).

## State commands — specification

Purpose
- Query the execution state for a given project/session on one or more Brokk instances. This command is useful for automation that needs to determine whether an instance is idle and safe to submit work, or is already running work and whether that work can be cancelled.

Command
- `brokkctl state get`

Global and command flags
- `--format json|text` — output format; `json` is canonical.
- `--instance <selector>` — select a specific instance (see selection rules).
- `--all` — query all non-stale instances (fan-out).
- `--path <abs-path>` or `--project-id <id>` — project scope (required; see semantics).
- `--session-id <id>` — optional session selector. If omitted, the instance's active session for the given project will be used when available (see semantics).
- `--require-active` — if set, treat missing active session as an error (USER_ERROR); otherwise `data.active` will be returned false.
- `--request-id <uuid>` — client-provided correlation id (optional).
- `--timeout <ms>` — overall timeout for discovery and per-request network ops.
- `--fail-fast` / `--best-effort` — fan-out failure policy.

Selectors / scoping semantics
- Project scope is required for `state get`. The caller must provide either `--path` or `--project-id`.
- `--session-id` is optional. When omitted the server SHOULD resolve to the active session for the provided project:
  - If an active session exists: state is returned for that session.
  - If no active session exists:
    - Default behavior: return `status: "ok"` with `data.active == false` and no execution running.
    - If `--require-active` is used: return `status: "error"` with code `NOT_FOUND`.
- For deterministic automation prefer specifying both `--path` and `--session-id`. For multi-instance operations use `--instance` or `--all` with explicit failure policy.

Behavior
- `state get` must be cheap and typically only returns metadata about currently running execution (if any). Servers SHOULD avoid expensive calculations when answering this query.
- When `--all` is used the client must aggregate results using the canonical fan-out envelope (`summary`, `results[]`) described elsewhere.
- If the instance can be reached but has no knowledge of the supplied project or session, the server returns a per-instance `NOT_FOUND` error (or `data.active == false` when using the non-failing default).
- If the instance is running an execution but is not able to share details due to security/policy, it should return `status: "ok"` with `data.masked == true` and minimal fields (e.g., `mode` omitted, `cancellable` false) and include an `error` with `code: "PERMISSION_DENIED"` in `details` only when appropriate for automation.

Execution state JSON schema (command → per-instance result)
Per-instance result container (canonical fields from the spec still apply):

```json
{
  "instanceId": "550e8400-e29b-41d4-a716-446655440000",
  "listenAddr": "127.0.0.1:54321",
  "status": "ok",
  "data": {
    "project": "/home/alice/project-a",
    "sessionId": "s-123",
    "active": true,
    "execution": {
      "state": "running",            // "idle" | "running"
      "mode": "ask",                // "ask" | "plan" | "code" | "lutz"
      "jobId": "j-9",               // optional: server job id when running
      "startedAtMs": 1690006000000, // epoch ms when execution started; null if idle
      "cancellable": true,          // whether client-initiated cancellation is possible
      "progress": {                 // optional progress information
        "phase": "planning",        // string: current phase name
        "percent": 42.5             // number from 0.0–100.0 when available
      },
      "details": {                  // optional string/object for diagnostics
        "note": "running external planner"
      }
    }
  },
  "error": null,
  "elapsedMs": 6
}
```

Field notes
- `data.active` (boolean): whether a session is active / selected for the supplied project.
- `execution.state`: coarse runtime state: `"idle"` or `"running"`.
- `execution.mode`: logical mode of execution. Canonical enumerated values: `"ask"`, `"plan"`, `"code"`, `"lutz"`. (Implementations may include other mode strings; clients should treat unknown mode strings as opaque capability hints.)
- `execution.startedAtMs`: epoch ms when the current execution started; null for idle.
- `execution.cancellable`: whether client can meaningfully request a cancellation for the running job (mapped to `execution.cancel`/`execution stop` semantics).
- `execution.jobId`: server-provided job identifier to use with cross-request correlate/cancel operations.
- `execution.progress`: optional progress information. Servers may omit if not available.

Per-instance error shapes
- If the instance cannot be reached: per-instance result with `status: "error"` and canonical `error` object (e.g., `TRANSPORT_ERROR`).
- If project not found on instance: `error.code == "NOT_FOUND"` and `error.details.attemptedPath`.
- If session not found and `--require-active` used: `error.code == "NOT_FOUND"` describing missing active session.
- If feature unsupported: `error.code == "PROTOCOL_UNSUPPORTED_FEATURE"`.

Aggregate (fan-out) response
- When `--all` is used return the standard fan-out envelope:
  - `requestId`, `summary` (requested/succeeded/failed), `results` (per-instance containers), `elapsedMs`.
- Mixed outcomes map to exit code `4` (PARTIAL_SUCCESS) in JSON mode, or a non-zero exit otherwise per overall exit-code mapping.

Examples

1) Idle session (single instance)

Command:
- `brokkctl state get --instance a111... --path /home/alice/project-a -o json`

Output:
```json
{
  "requestId": "req-state-1",
  "results": [
    {
      "instanceId": "a111...",
      "status": "ok",
      "data": {
        "project": "/home/alice/project-a",
        "sessionId": "s-123",
        "active": true,
        "execution": {
          "state": "idle",
          "mode": null,
          "jobId": null,
          "startedAtMs": null,
          "cancellable": false
        }
      },
      "error": null,
      "elapsedMs": 3
    }
  ],
  "summary": { "requested": 1, "succeeded": 1, "failed": 0 }
}
```

2) Running execution (single instance)

Command:
- `brokkctl state get --instance a111... --path /home/alice/project-a --session-id s-123 -o json`

Output:
```json
{
  "requestId": "req-state-2",
  "results": [
    {
      "instanceId": "a111...",
      "status": "ok",
      "data": {
        "project": "/home/alice/project-a",
        "sessionId": "s-123",
        "active": true,
        "execution": {
          "state": "running",
          "mode": "plan",
          "jobId": "j-42",
          "startedAtMs": 1690007000000,
          "cancellable": true,
          "progress": { "phase": "planning", "percent": 12.0 },
          "details": { "planner": "fast-planner-v2" }
        }
      },
      "error": null,
      "elapsedMs": 12
    }
  ],
  "summary": { "requested": 1, "succeeded": 1, "failed": 0 }
}
```

3) Missing active session (default, non-failing)

Command:
- `brokkctl state get --instance a111... --path /home/alice/project-a -o json`

Output:
```json
{
  "requestId": "req-state-3",
  "results": [
    {
      "instanceId": "a111...",
      "status": "ok",
      "data": {
        "project": "/home/alice/project-a",
        "sessionId": null,
        "active": false,
        "execution": {
          "state": "idle",
          "mode": null,
          "jobId": null,
          "startedAtMs": null,
          "cancellable": false
        }
      },
      "error": null,
      "elapsedMs": 2
    }
  ],
  "summary": { "requested": 1, "succeeded": 1, "failed": 0 }
}
```

Implementation hints
- Servers should implement `ctl-info` and a lightweight `state` endpoint (e.g., `GET /v1/state?project=...&sessionId=...`) that returns the above per-instance shape.
- Keep `state get` response small and suitable for frequent polling by automation.
- Use `execution.jobId` so `brokkctl execution cancel --job <jobId>` or equivalent can correlate and cancel running jobs.

Security and privacy
- Do not expose sensitive execution internals by default. If a server masks details for security reasons, set `execution.cancellable` conservatively (usually `false`) and include a `details.maskedReason` or `error` as appropriate.

Exit codes
- On success: `0` when all targeted instances returned `status: "ok"`.
- On per-instance mixed results: `4` (PARTIAL_SUCCESS) in JSON mode.
- On transport/auth errors: appropriate mapping per the JSON exit-code mapping defined earlier.

## History commands — specification

Purpose
- Provide a machine-friendly, deterministic representation of session/output history produced by Brokk instances (LLM transcripts, task events, notifications, diffs, and related output).
- Support both paged retrieval (`history get`) and streaming/tailing (`history tail --follow`) with NDJSON for tooling friendliness.
- Define multi-instance aggregation and per-instance cursor semantics so automation can tail across multiple instances deterministically and resume without missing or duplicating events.

Terminology
- history entry / event: a single recorded output item (LLM text block, executor event, notification, diff, etc.) emitted by an instance and stored in session history.
- sequence: monotonically-increasing integer sequence the instance assigns to events for a given session (instance-scoped).
- cursor: opaque token provided by the server that encodes the resume position for continued paging or tailing. For multi-instance tails, clients will maintain one cursor per instance.
- NDJSON event line: a single JSON object per line for streaming/tail mode.

Canonical history entry shape (single event)
- Each history event returned in `-o json` (non-streaming) or as an NDJSON line (streaming) SHOULD follow this shape:

{
  "instanceId": "550e8400-e29b-41d4-a716-446655440000",
  "sessionId": "s-123",
  "sequence": 12345,
  "createdAtMs": 1690005000000,
  "eventType": "assistant.output|user.input|job.event|notification|diff|file.patch",
  "author": "assistant|user|system",
  "text": "Partial or full textual output (may be null for structured events)",
  "payload": { /* optional structured event data, e.g., { "jobId": "j-1", "phase": "planning", ... } */ },
  "tags": ["stdout","final"],
  "metadata": { "language":"java", "model":"gpt-4o-mini" },
  "cursor": "opaque-instance-cursor-token"
}

Field notes
- `instanceId` (string): origin instance (always present in multi-instance contexts).
- `sessionId` (string|null): session this event belongs to; null for global/system events.
- `sequence` (number): strictly monotonic integer assigned by the instance per session (or per-instance if session-scoped sequences are not available); useful for ordering and resumption.
- `createdAtMs` (number): epoch ms timestamp of the event.
- `eventType` (string): coarse event classification (enumerated values recommended).
- `text` (string|null): human-usable textual portion; servers may chunk very long outputs across multiple events.
- `payload` (object|null): structured event data for non-text events (job signals, diffs, diagnostics).
- `cursor` (string): server-supplied opaque resume token representing the position immediately after this event (useful for tail and subsequent `history get` calls).

history get — semantics & paging
- Purpose: fetch a bounded page of historical events for a given session (or project/global scope when supported).
- Inputs/common flags:
  - `--instance <selector>` (single-instance recommended; `--all` supported for aggregation).
  - `--session-id <id>` (required when scoping to a session).
  - `--from-seq <n>` (inclusive start sequence) OR `--since-ms <ms>` (inclusive start timestamp). If omitted, server returns most-recent page.
  - `--limit <n>` (page size, default: 100, max: server-defined).
  - `--cursor <opaque-token>`: resume token previously returned by the server (preferred for correctness).
  - `--order asc|desc` (optional; default: asc by sequence).
  - `--event-type <...>` and `--tag <...>` filters (optional).
  - `--request-id`, `--timeout`, `--format`.

- Pagination model:
  - Cursor-based paging is the recommended default: server returns `nextCursor` that clients can pass to fetch the next page. Cursor encodes both sequence and server-side pagination state.
  - Additionally support limit + from-seq/from-ms for convenience, but `cursor` is authoritative for resumption.
  - When `order=asc` and `cursor` points to position P, server returns events with sequence > P (or timestamp > P) up to `limit`. When `order=desc`, semantics reverse.

- Non-streaming response (JSON mode)
Top-level envelope:

{
  "requestId": "uuid",
  "summary": { "returned": 3, "requested": 3 },
  "events": [ /* array of history entry objects as above (ordered per `order`) */ ],
  "nextCursor": "opaque-next-cursor-or-null",
  "elapsedMs": 18
}

- Edge cases:
  - If no events exist, `events` is empty and `nextCursor` is null.
  - `nextCursor == null` signals end-of-history for the requested window.

history tail — streaming semantics (`--follow`)
- Purpose: stream (tail) new history events as they are produced by an instance. Use NDJSON for line-delimited streaming so tools can parse incrementally.
- Inputs:
  - `--instance <selector>` or `--all`
  - `--session-id <id>` (session-scoped tail)
  - `--cursor <opaque-token>` or `--since-seq <n>` / `--since-ms <ms>`: starting position; when omitted client receives new events only.
  - `--request-id`, `--timeout`, `--format ndjson`
  - `--follow`: enable streaming (server returns NDJSON).
- Behavior:
  - Server responds with one NDJSON object per event line. Each line is a self-contained event envelope (see canonical history entry shape). Events include `cursor` so the client can persist resume points.
  - Servers SHOULD periodically emit heartbeat lines (e.g., `{ "type":"heartbeat", "nowMs": ... }`) or SSE comments in long idle periods to keep connections alive; chaseable by connection-level semantics.
  - On connection close (client disconnect or server restart) the client may resume by issuing `history tail --cursor <last-cursor-per-instance>` for each instance it is following.

NDJSON line shapes
- Event line:
{ "requestId":"...", "instanceId":"a111...", "sessionId":"s-1", "sequence": 100, "createdAtMs": 1690006000000, "eventType":"assistant.output", "text":"Partial reply", "payload":null, "cursor":"inst:a111:seq:100" }

- Control line (heartbeats / info):
{ "requestId":"...", "type":"heartbeat", "nowMs":1690006005000 }

Multi-instance aggregation rules
- For `--all` non-streaming `history get`:
  - Return an aggregated envelope with `summary` and `events` array containing per-event `instanceId`. Ordering is by `createdAtMs` then by `instanceId` then `sequence` to make ordering deterministic across instances; but clients MUST treat per-instance sequence as authoritative for resumption.
  - Provide `nextCursors` map when `cursor`-style pagination is used across instances:

{
  "requestId": "uuid",
  "summary": { "returned": 6, "requested": 6 },
  "events": [ ... ],
  "nextCursors": { "a111...": "cursor-a111:200", "b222...": "cursor-b222:150" },
  "elapsedMs": 50
}

- For `--all --follow` (tail across multiple instances):
  - The server SHOULD stream events as they arrive from any instance, interleaving them by arrival time. Each event line MUST include `instanceId`, `sequence`, and `cursor`.
  - Clients MUST maintain one cursor per instance. On reconnect or resume, clients supply a per-instance cursor map. For example, the client may pass `--cursor-file` or multiple `--cursor instanceId=opaqueCursor` parameters; the exact CLI parameterization is an implementation detail but the protocol must support per-instance cursors.
  - When resuming, servers MUST honor the per-instance cursor values to avoid duplicates and should provide the first event with sequence > the provided cursor.

Per-instance cursors in aggregated responses
- For aggregated `history get`/pagination and for `history tail` resumability, servers SHOULD include `nextCursors` or include `cursor` on each event line. Clients should persist the last-seen cursor for each instance for reliable resume.

Example: `history get` (single-instance)
Command:
- brokkctl history get --instance a111... --session-id s-1 --limit 3 -o json

Response:
{
  "requestId": "req-100",
  "summary": { "returned": 3, "requested": 3 },
  "events": [
    {
      "instanceId": "a111...",
      "sessionId": "s-1",
      "sequence": 100,
      "createdAtMs": 1690006000000,
      "eventType": "user.input",
      "author": "user",
      "text": "Search for helper method",
      "payload": null,
      "tags": ["stdin"],
      "metadata": {},
      "cursor": "inst:a111:seq:100"
    },
    {
      "instanceId": "a111...",
      "sessionId": "s-1",
      "sequence": 101,
      "createdAtMs": 1690006001000,
      "eventType": "assistant.output",
      "author": "assistant",
      "text": "I found two candidates...",
      "payload": null,
      "tags": ["stdout","partial"],
      "metadata": {},
      "cursor": "inst:a111:seq:101"
    },
    {
      "instanceId": "a111...",
      "sessionId": "s-1",
      "sequence": 102,
      "createdAtMs": 1690006002000,
      "eventType": "assistant.output",
      "author": "assistant",
      "text": "Full patch applied in file X",
      "payload": { "jobId":"j-9","status":"complete" },
      "tags": ["stdout","final"],
      "metadata": {},
      "cursor": "inst:a111:seq:102"
    }
  ],
  "nextCursor": "inst:a111:seq:102",
  "elapsedMs": 12
}

Example: tailing across `--all` with per-instance cursors (NDJSON)
- Client starts with cursors for instances `a111...` and `b222...` obtained earlier, then tails:

Client invocation (conceptual):
- brokkctl history tail --all --session-id s-1 --cursor a111=inst:a111:seq:102 --cursor b222=inst:b222:seq:148 --follow -o ndjson

Server NDJSON stream (each line is a JSON object):

Line 1 (event from a111):
{ "requestId":"req-tail-1","instanceId":"a111...","sessionId":"s-1","sequence":103,"createdAtMs":1690006003000,"eventType":"assistant.output","author":"assistant","text":"Continuing...", "payload":null, "tags":["stdout"], "cursor":"inst:a111:seq:103" }

Line 2 (event from b222):
{ "requestId":"req-tail-1","instanceId":"b222...","sessionId":"s-1","sequence":149,"createdAtMs":1690006003500,"eventType":"assistant.output","author":"assistant","text":"Found a TODO in file Y", "payload":null, "tags":["stdout"], "cursor":"inst:b222:seq:149" }

Line 3 (heartbeat/info):
{ "requestId":"req-tail-1","type":"heartbeat","nowMs":1690006005000 }

Line 4 (event from a111):
{ "requestId":"req-tail-1","instanceId":"a111...","sessionId":"s-1","sequence":104,"createdAtMs":1690006007000,"eventType":"job.event","author":"system","text":null,"payload":{"jobId":"j-10","phase":"planning"},"cursor":"inst:a111:seq:104" }

- On each line the client persists the `cursor` value for the corresponding `instanceId`. If the connection drops, the client reconnects and provides the last seen cursor for each instance so that the server resumes after those positions.

Resumption protocol (recommended)
- Persist last-seen cursor per instance.
- On reconnect, call `history tail --all --cursor <instanceId>=<cursor>` for each instance.
- Servers must return only events with sequence > provided cursor for that instance.

Error handling in streaming
- If an instance becomes unreachable during an aggregated tail:
  - The server SHOULD emit an NDJSON error envelope for that instance: { "requestId":"...","instanceId":"b222...","error":{ "code":"TRANSPORT_ERROR","message":"connection lost","details":{} } }
  - The overall TCP/HTTP connection remains open if other instances still stream events; clients may choose to retry probes for unreachable instances separately.
- If `--fail-fast` is configured for multi-instance tails, client behavior governs whether to close other streams on first error. Default safe behavior is best-effort (keep streaming available events).

Best practices & implementation hints
- Prefer cursor-based resumption for correctness. Sequence numbers alone are useful for ordering but cursor tokens can encode server-side state (sharding, truncation).
- For multi-instance aggregates, always include `instanceId` and `cursor` on each event so clients can resume precisely per-origin.
- Keep NDJSON lines small and self-contained so line-by-line tools (jq, tail -f) work well.
- Servers may truncate history to a retention window; cursors that fall before the window should cause the server to respond with a `cursorExpired` error and a suggested start position (e.g., `from-seq` or earliest available cursor).

## Appendix: Example Shapes

Instance descriptor (discovery)
```json
{
  "instanceId": "550e8400-e29b-41d4-a716-446655440000",
  "pid": 12345,
  "listenAddr": "127.0.0.1:54321",
  "project": "/home/alice/my-repo",
  "brokkctlVersion": "1.0.0",
  "lastSeenMs": 1690000000000
}
```

Fan-out response (uses canonical envelopes)
```json
{
  "requestId": "550e8400-e29b-41d4-a716-446655440000",
  "summary": { "requested": 3, "succeeded": 2, "failed": 1 },
  "results": [
    { "instanceId":"a","status":"ok","data":{ /* ... */ }, "error": null },
    { "instanceId":"b","status":"ok","data":{ /* ... */ }, "error": null },
    { "instanceId":"c","status":"error","data":null,"error":{"code":"BUSY","message":"instance is busy"} }
  ]
}
```

---
This specification is intentionally concise and implementation-agnostic while providing actionable rules for discovery, negotiation, compatibility, error handling, and output shapes. The next phase is a reference implementation that selects a discovery mechanism and wires the `ctl-info` endpoint on the Brokk side and a minimal `brokkctl` client that implements the negotiation and JSON-first output.

## Appendix: Transport mapping and control-facade guidance

This appendix maps each high-level `brokkctl` command area to the intended future automation surfaces (REST, MCP, AppleScript) and documents recommendations for keeping the in-process control facade transport-agnostic. The objective is that all transports reuse the same DTOs, identifiers and semantics so clients can migrate between REST/MCP/AppleScript without behavioral surprises.

### High-level mapping (command → transport surfaces)

- instances
  - REST: GET /v1/instances, POST /v1/instances/prune
  - MCP: command `instances.list` / `instances.prune` (canonical request envelope)
  - AppleScript: `instancesList()` / `instancesPrune()` returning JSON string (or structured record)
  - Notes: Discovery and registry semantics are identical across transports. `ctl-info` is the core per-instance REST endpoint; MCP should mirror that via `ctl-info` command.

- projects
  - REST: GET /v1/projects, POST /v1/projects/open
  - MCP: command `projects.list` / `projects.open`
  - AppleScript: `projectsList()` / `projectsOpen(path)` returning canonical JSON envelopes
  - Notes: Use canonical project identity (`path` and optional `projectId`) across transports.

- sessions
  - REST: GET /v1/sessions/active, GET /v1/sessions, POST /v1/sessions, POST /v1/sessions/switch
  - MCP: `sessions.active` / `sessions.list` / `sessions.create` / `sessions.switch`
  - AppleScript: `sessionActive(projectPath)` / `sessionCreate(...)`
  - Notes: Prefer `sessionId` as the authoritative selector in automation; `name` is convenience.

- context
  - REST: GET/POST/DELETE /v1/context
  - MCP: `context.list` / `context.add` / `context.remove`
  - AppleScript: `contextList(projectPath, sessionId)` and variants; content-heavy ops return or accept JSON payloads
  - Notes: Use `contextId` and `relativePath` consistently. Large content should be uploaded/pushed over transport-specific mechanisms (HTTP body, MCP base64 or file descriptor, AppleScript file references).

- execution (exec / jobs)
  - REST: POST /v1/execution (start), POST /v1/execution/{jobId}/stop, GET /v1/execution/{jobId}/events (poll/stream)
  - MCP: `execution.start` / `execution.stop` and an optional streaming channel (NDJSON lines on stdout)
  - AppleScript: `execStart(...)` returns `jobId` and optionally a follow handle; streaming via callback/listener pattern that returns NDJSON string chunks
  - Notes: Streaming semantics (NDJSON) must be identical across transports. REST can use SSE/Chunked NDJSON; MCP should stream one JSON object per line; AppleScript should expose a streaming adapter that returns the same JSON envelope content.

- state
  - REST: GET /v1/state
  - MCP: `state.get`
  - AppleScript: `stateGet(projectPath, sessionId)`
  - Notes: Response schema must match control facade DTO for `execution` and `cancellable` fields.

- history
  - REST: GET /v1/history (paged), GET /v1/history/tail (stream)
  - MCP: `history.get` / `history.tail` (NDJSON)
  - AppleScript: `historyGet(...)` / `historyTail(...)` returning JSON events or NDJSON text
  - Notes: Cursor semantics are per-instance and must be preserved across transports.

### Transport-agnostic control facade design recommendations

1. Single in-process API (Control Facade)
   - Implement a single Java-facing control facade (e.g., `ControlFacade` or `CtlService`) that exposes strongly-typed methods for each command area:
     - instances(): List<InstanceDto>
     - openProject(path): ProjectOpenResultDto
     - createSession(...): SessionDto
     - addContext(...): ContextAddResultDto
     - startExecution(JobSpec): JobDescriptorDto
     - stopExecution(jobId, mode): StopResultDto
     - getState(...): StateDto
     - historyGet(...): HistoryPageDto
   - Transport adapters (HTTP, MCP stdio, AppleScript bridge) should be thin wrappers that translate transport-specific wire formats into the control-facade DTOs and vice versa.

2. Reuse canonical DTOs and envelopes
   - Reuse the same canonical request and response envelopes defined in this spec for all transports:
     - Request envelope: { requestId, createdAtMs, command, protocolVersion, payload }
     - Per-instance result container and canonical Error object.
   - Transport adapters only translate serialization (JSON, NDJSON, AppleScript native types), but not semantics.

3. Stable, minimal identifiers
   - Use stable primitive identifiers across transports:
     - instanceId, sessionId, projectId, contextId, jobId, cursor tokens.
   - Avoid embedding transient runtime objects (file descriptors, platform handles) in DTOs. Represent them as strings or opaque tokens.

4. Avoid UI coupling
   - DTOs returned by the facade must not contain UI objects or UI-specific state (Swing components, OS window handles, etc.). Provide only machine-friendly fields: normalized paths, timestamps, version strings, capability lists, and explicit flags (e.g., `readOnly`, `isActive`).
   - If a UI-only field is useful for humans (e.g., friendly display name), mark it optional and non-authoritative (clients should not use it for programmatic decisions).

5. Capability & version negotiation
   - Expose `supportedCapabilities` and `brokkctlVersion` via `ctl-info` (or equivalent MCP `ctl-info` command) and use `Brokk-CTL-Version` header in all transports when supported.
   - Transport adapters must forward the `Brokk-CTL-Version` header where applicable (HTTP). For MCP/AppleScript, include `protocolVersion` in the request envelope.

6. Streaming parity
   - Streaming semantics must be identical across transports:
     - NDJSON line-per-event shape is canonical.
     - Each event must include `requestId`, `instanceId`, `cursor`.
     - Implementations should provide heartbeat lines for long-idle streams.
   - REST should support SSE or chunked NDJSON; MCP should stream NDJSON over stdout; AppleScript bridges should provide a callback or a polling loop that yields the same NDJSON lines.

7. Error model parity
   - All transports must represent errors using the canonical Error object shape { code, message, details } in JSON mode. For streaming errors, emit an error envelope as a single NDJSON line.
   - Exit code semantics apply to CLI tooling; transports should map internal error codes to the same canonical code names for machine clients.

8. Content transfer strategies
   - For large content (files, patches): prefer transport-agnostic references in DTOs (e.g., `artifactRef`, `uploadUrl`) rather than inlining large blobs in the core DTOs.
   - REST may offer multipart or direct object storage upload URLs; MCP can agree on a follow-up `content.upload` command or base64-encoded bodies; AppleScript may pass a filesystem path that the instance can read (with permission checks).

9. AppleScript-specific guidance
   - Provide a small AppleScript adapter that converts script calls into the canonical control-facade calls and returns JSON strings or native AppleScript records that mirror DTO fields.
   - Because AppleScript lacks streaming primitives, expose streaming via a helper that writes NDJSON lines to a file or a callback mechanism that AppleScript clients can poll.

10. Security and auth consistency
    - This controller is intended for local-only usage. Prefer a simple shared local key rather than bearer tokens.
    - Across transports:
      - HTTP: send `Brokk-CTL-Key: <key>` on every request.
      - MCP/AppleScript: include `ctlKey` in the request envelope (or equivalent metadata channel).
    - The shared key must be stored in a well-known per-user location on disk that both the instance and `brokkctl` can read.
    - The facade should perform consistent permission checks regardless of transport and return identical Error codes for permission-related failures.

### Practical migration advice

- First implement and stabilize the in-process control facade and DTOs.
- Implement the REST adapter using the facade and reuse the same JSON DTOs for the wire format.
- Implement an MCP adapter that accepts the canonical request envelope on stdin/stdout and streams NDJSON lines for events; reuse the same DTO JSON serialization code.
- Implement AppleScript last as a thin bridge that translates AppleScript invocations into Control Facade calls and returns JSON/records; this minimizes AppleScript-specific complexity while preserving automation parity.

### Quick reference: DTOs that must be stable and transport-agnostic

- InstanceDto: { instanceId, pid, listenAddr, projects?, project?, brokkctlVersion, startedAt, lastSeenMs, platform, listenProtocol }
- ProjectDto: { path, projectId?, name?, lastOpenedMs?, status }
- SessionDto: { sessionId, name, createdAtMs, lastActiveMs, isActive, project }
- ContextEntryDto: { contextId, type, relativePath?, addedAtMs, sizeBytes, digest?, sessionId? }
- JobSpec / JobDescriptorDto: { jobId, mode, startedAtMs, cursor?, followUrl? }
- HistoryEventDto / StreamEventDto: { requestId, instanceId, jobId?, sequence, createdAtMs, eventType, text?, payload?, cursor }

---

Adhering to these mapping and facade principles will ensure Brokk's automation surfaces remain consistent, testable, and easy for external tools to adopt, whether they speak REST, MCP, or AppleScript.
