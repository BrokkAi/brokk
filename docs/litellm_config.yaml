model_list:
  - model_name: o3
    litellm_params:
      model: openai/o3
      api_key: "os.environ/OPENAI_API_KEY"
    model_info:
      is_reasoning: true
      free_tier_eligible: false
      is_private: true

  - model_name: o4-mini
    litellm_params:
      model: openai/o4-mini
      api_key: "os.environ/OPENAI_API_KEY"
    model_info:
      is_reasoning: true
      free_tier_eligible: false
      is_private: true

  - model_name: gpt-4.1
    litellm_params:
      model: openai/gpt-4.1
      api_key: "os.environ/OPENAI_API_KEY"
    model_info:
      is_reasoning: false
      free_tier_eligible: false
      is_private: true

  - model_name: gpt-4.1-nano
    litellm_params:
      model: openai/gpt-4.1-nano
      api_key: "os.environ/OPENAI_API_KEY"
    model_info:
      is_reasoning: false
      free_tier_eligible: true
      is_private: true

  - model_name: gemini-2.5-pro
    litellm_params:
      model: gemini/gemini-2.5-pro-preview-05-06
      api_key: "os.environ/GEMINI_API_KEY"
    model_info:
      supports_reasoning: true # override incorrect default
      is_reasoning: true
      free_tier_eligible: false
      is_private: true

  - model_name: gemini-2.5-flash
    litellm_params:
      model: gemini/gemini-2.5-flash-preview-04-17
      api_key: "os.environ/GEMINI_API_KEY"
    model_info:
      is_reasoning: true
      free_tier_eligible: false
      is_private: true

  - model_name: gemini-2.0-flash
    litellm_params:
      model: gemini/gemini-2.0-flash
      api_key: "os.environ/GEMINI_API_KEY"
    model_info:
      is_reasoning: false
      free_tier_eligible: true
      is_private: true

  - model_name: gemini-2.0-flash-lite
    litellm_params:
      model: gemini/gemini-2.0-flash-lite
      api_key: "os.environ/GEMINI_API_KEY"
    model_info:
      is_reasoning: false
      free_tier_eligible: true
      is_private: true

  - model_name: claude-3.7-sonnet
    litellm_params:
      model: anthropic/claude-3-7-sonnet-latest
      api_key: "os.environ/ANTHROPIC_API_KEY"
    model_info:
      is_reasoning: false
      free_tier_eligible: false
      is_private: true
      # Anthropic errors out if input + max_output > 200k. Default max_output is 128k,
      # which is weighted the wrong way for typical coding tasks
      max_output_tokens: 32768

  - model_name: claude-3.5-sonnet
    litellm_params:
      model: anthropic/claude-3-5-sonnet-latest
      api_key: "os.environ/ANTHROPIC_API_KEY"
    model_info:
      is_reasoning: false
      free_tier_eligible: false
      is_private: true

  - model_name: deepseek-R1
    litellm_params:
      model: deepseek/deepseek-reasoner
      api_key: "os.environ/DEEPSEEK_API_KEY"
    model_info:
      is_reasoning: true
      free_tier_eligible: false
      is_private: false

  - model_name: deepseek-v3
    litellm_params:
      model: deepseek/deepseek-chat
      api_key: "os.environ/DEEPSEEK_API_KEY"
    model_info:
      is_reasoning: false
      free_tier_eligible: true
      is_private: false

  - model_name: grok-3-beta
    litellm_params:
      model: xai/grok-3-beta
      api_key: "os.environ/GROK_API_KEY"
    model_info:
      is_reasoning: true
      free_tier_eligible: false
      is_private: true

  - model_name: grok-3-fast-beta
    litellm_params:
      model: xai/grok-3-fast-beta
      api_key: "os.environ/GROK_API_KEY"
    model_info:
      is_reasoning: true
      free_tier_eligible: false
      is_private: true

  - model_name: grok-3-mini-beta
    litellm_params:
      model: xai/grok-3-mini-beta
      api_key: "os.environ/GROK_API_KEY"
    model_info:
      is_reasoning: true
      free_tier_eligible: true
      is_private: true

  - model_name: gpt-4o-transcribe
    litellm_params:
      model: openai/gpt-4o-transcribe
      api_key: "os.environ/OPENAI_API_KEY"
    model_info:
      free_tier_eligible: true

litellm_settings:
  num_retries: 0
